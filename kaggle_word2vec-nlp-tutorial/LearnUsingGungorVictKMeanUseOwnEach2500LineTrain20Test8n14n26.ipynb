{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!The data file Gungor_2018_VictorianAuthorAttribution_data-train.csv can be obtained from https://archive.ics.uci.edu/ml/machine-learning-databases/00454/\n",
    "\n",
    "##input data\n",
    "import pandas as pd\n",
    "\n",
    "#note: use your own path\n",
    "path_to_datafile = '..//..//DS7004//u1720146_DS7004_courseworkCodeAndData//preparationWorks//fromDS7003_Gungor2018VictorianAuthorAttribution_NGram//Gungor_2018_VictorianAuthorAttribution_data-train.csv'\n",
    "pathToGungorVict = path_to_datafile\n",
    "gungorVictRow = pd.read_csv(pathToGungorVict, encoding = 'ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##form training data (2500 lines x 3) and test data (20 x 3)\n",
    "##each line about 1000 words\n",
    "#Use three authors' data:\n",
    "#author:8 Charles Dickens total lines: 6914/ 14 George Eliot 2696/ 26 Jane Austen 4441\n",
    "#each first 2500 lines for training, last 20 lines for testing. Each line has 1000 words\n",
    "for i in [14, 26, 8]:\n",
    "    allLines = gungorVictRow.loc[gungorVictRow['author'] == i]\n",
    "    lines2500 = allLines.iloc[0:2500]\n",
    "    linesLast20 = allLines.iloc[-20:]\n",
    "    try:\n",
    "        train = train.append(lines2500)\n",
    "        test = test.append(linesLast20)\n",
    "    except:\n",
    "        train = lines2500\n",
    "        test = linesLast20\n",
    "train = train.sample(frac=1, random_state=42).reset_index(drop = True) #7500 lines suffled\n",
    "test = test.sample(frac=1, random_state=42).reset_index(drop = True) #60 lines suffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import various modules for forming a string cleaning function\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_to_wordlist( text, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    text = BeautifulSoup(text).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \", text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:  #These three lines will not be used. Pleasesee the second parameter of this function\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download the punkt tokenizer and form a sentence splitting function\n",
    "import nltk.data\n",
    "#nltk.download() #no need to use this line again after it has been used once  \n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "# Define a function to split a text into parsed sentences\n",
    "def text_to_sentences( text, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a text into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(text.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call text_to_wordlist to get a list of words\n",
    "            sentences.append( text_to_wordlist( raw_sentence,               remove_stopwords )) #defined as false in text_to_wordlist\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences\n",
    "\n",
    "#function for parsing the training set\n",
    "def parsing_sentence_set(text_df):\n",
    "    sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "    print(\"Parsing sentences from training set\")\n",
    "    for text in text_df[\"text\"]:\n",
    "        sentences += text_to_sentences(text, tokenizer)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "##use the functions to form a cleaned unlabelled training set\n",
    "##for performming unsupervised learning\n",
    "sentences = parsing_sentence_set(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',    level=logging.INFO)\n",
    "\n",
    "# Set values for the single neural network layer's various parameters\n",
    "#num_features = 300    # Word vector dimensionality                      \n",
    "#min_word_count = 40   # Minimum word count                        \n",
    "#num_workers = 4       # Number of threads to run in parallel\n",
    "#context = 10          # Context window size\n",
    "#downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 5    # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 6           # Context window size         \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "epochs= 20             #number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initialize and train the model (this will take some time)\n",
    "# need to install gensim's word2vec\n",
    "from gensim.models import word2vec\n",
    "def form_model_from_sentences(sentences):\n",
    "    print(\"Training model...\")\n",
    "    model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                size=num_features, min_count = min_word_count,\\\n",
    "                window = context, sample = downsampling, iter = epochs)\n",
    "\n",
    "    # If you don't plan to train the model any further, calling \n",
    "    # init_sims will make the model much more memory-efficient.\n",
    "    model.init_sims(replace=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-24 02:31:39,409 : INFO : collecting all words and their counts\n",
      "2020-08-24 02:31:39,410 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-24 02:31:40,509 : INFO : collected 9976 word types from a corpus of 7435641 raw words and 7500 sentences\n",
      "2020-08-24 02:31:40,509 : INFO : Loading a fresh vocabulary\n",
      "2020-08-24 02:31:40,525 : INFO : effective_min_count=5 retains 9940 unique words (99% of original 9976, drops 36)\n",
      "2020-08-24 02:31:40,526 : INFO : effective_min_count=5 leaves 7435530 word corpus (99% of original 7435641, drops 111)\n",
      "2020-08-24 02:31:40,553 : INFO : deleting the raw counts dictionary of 9976 items\n",
      "2020-08-24 02:31:40,553 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2020-08-24 02:31:40,554 : INFO : downsampling leaves estimated 5250158 word corpus (70.6% of prior 7435530)\n",
      "2020-08-24 02:31:40,582 : INFO : estimated required memory for 9940 words and 300 dimensions: 28826000 bytes\n",
      "2020-08-24 02:31:40,582 : INFO : resetting layer weights\n",
      "2020-08-24 02:31:42,249 : INFO : training model with 4 workers on 9940 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=6\n",
      "2020-08-24 02:31:43,253 : INFO : EPOCH 1 - PROGRESS: at 24.93% examples, 1306777 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:44,262 : INFO : EPOCH 1 - PROGRESS: at 51.20% examples, 1337130 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:45,263 : INFO : EPOCH 1 - PROGRESS: at 77.60% examples, 1353180 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:46,083 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:31:46,096 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:31:46,098 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:31:46,100 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:31:46,101 : INFO : EPOCH - 1 : training on 7435641 raw words (5249925 effective words) took 3.8s, 1364115 effective words/s\n",
      "2020-08-24 02:31:47,111 : INFO : EPOCH 2 - PROGRESS: at 27.07% examples, 1410719 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:48,112 : INFO : EPOCH 2 - PROGRESS: at 52.80% examples, 1379690 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-24 02:31:49,119 : INFO : EPOCH 2 - PROGRESS: at 77.87% examples, 1355933 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:49,957 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:31:49,969 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:31:49,971 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:31:49,971 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:31:49,972 : INFO : EPOCH - 2 : training on 7435641 raw words (5250362 effective words) took 3.9s, 1357304 effective words/s\n",
      "2020-08-24 02:31:50,982 : INFO : EPOCH 3 - PROGRESS: at 23.47% examples, 1223395 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:51,983 : INFO : EPOCH 3 - PROGRESS: at 47.20% examples, 1233089 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:52,983 : INFO : EPOCH 3 - PROGRESS: at 71.20% examples, 1241774 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:53,987 : INFO : EPOCH 3 - PROGRESS: at 95.20% examples, 1245361 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:54,154 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:31:54,159 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:31:54,162 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:31:54,167 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:31:54,168 : INFO : EPOCH - 3 : training on 7435641 raw words (5250202 effective words) took 4.2s, 1251938 effective words/s\n",
      "2020-08-24 02:31:55,180 : INFO : EPOCH 4 - PROGRESS: at 22.80% examples, 1185292 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:56,181 : INFO : EPOCH 4 - PROGRESS: at 45.47% examples, 1187342 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:57,181 : INFO : EPOCH 4 - PROGRESS: at 69.87% examples, 1218001 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:58,183 : INFO : EPOCH 4 - PROGRESS: at 95.20% examples, 1245439 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:31:58,362 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:31:58,366 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:31:58,374 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:31:58,377 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:31:58,378 : INFO : EPOCH - 4 : training on 7435641 raw words (5250232 effective words) took 4.2s, 1247835 effective words/s\n",
      "2020-08-24 02:31:59,384 : INFO : EPOCH 5 - PROGRESS: at 25.33% examples, 1324180 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:00,384 : INFO : EPOCH 5 - PROGRESS: at 50.13% examples, 1312592 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-24 02:32:01,391 : INFO : EPOCH 5 - PROGRESS: at 75.20% examples, 1310728 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-24 02:32:02,397 : INFO : EPOCH 5 - PROGRESS: at 99.60% examples, 1301640 words/s, in_qsize 3, out_qsize 1\n",
      "2020-08-24 02:32:02,398 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:02,400 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:02,405 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:02,409 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:02,410 : INFO : EPOCH - 5 : training on 7435641 raw words (5248384 effective words) took 4.0s, 1302613 effective words/s\n",
      "2020-08-24 02:32:03,416 : INFO : EPOCH 6 - PROGRESS: at 23.73% examples, 1238875 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:04,418 : INFO : EPOCH 6 - PROGRESS: at 47.73% examples, 1248919 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:05,418 : INFO : EPOCH 6 - PROGRESS: at 71.73% examples, 1252193 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:06,418 : INFO : EPOCH 6 - PROGRESS: at 95.60% examples, 1252530 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:06,581 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:06,586 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:06,588 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:06,605 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:06,606 : INFO : EPOCH - 6 : training on 7435641 raw words (5250249 effective words) took 4.2s, 1251821 effective words/s\n",
      "2020-08-24 02:32:07,609 : INFO : EPOCH 7 - PROGRESS: at 22.93% examples, 1203050 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:08,613 : INFO : EPOCH 7 - PROGRESS: at 46.27% examples, 1211357 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:09,616 : INFO : EPOCH 7 - PROGRESS: at 69.87% examples, 1219205 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:10,618 : INFO : EPOCH 7 - PROGRESS: at 92.93% examples, 1216435 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:10,901 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:10,909 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:10,914 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:10,918 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:10,919 : INFO : EPOCH - 7 : training on 7435641 raw words (5249569 effective words) took 4.3s, 1217903 effective words/s\n",
      "2020-08-24 02:32:11,922 : INFO : EPOCH 8 - PROGRESS: at 22.53% examples, 1181775 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:12,930 : INFO : EPOCH 8 - PROGRESS: at 45.60% examples, 1191201 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:13,930 : INFO : EPOCH 8 - PROGRESS: at 68.53% examples, 1195328 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:14,930 : INFO : EPOCH 8 - PROGRESS: at 92.13% examples, 1206200 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:15,251 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:15,254 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:15,259 : INFO : worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-24 02:32:15,264 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:15,265 : INFO : EPOCH - 8 : training on 7435641 raw words (5249035 effective words) took 4.3s, 1208587 effective words/s\n",
      "2020-08-24 02:32:16,276 : INFO : EPOCH 9 - PROGRESS: at 23.20% examples, 1205408 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:17,282 : INFO : EPOCH 9 - PROGRESS: at 46.67% examples, 1215283 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:18,283 : INFO : EPOCH 9 - PROGRESS: at 69.47% examples, 1208501 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:19,287 : INFO : EPOCH 9 - PROGRESS: at 91.47% examples, 1194501 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:19,629 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:19,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:19,645 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:19,648 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:19,649 : INFO : EPOCH - 9 : training on 7435641 raw words (5249965 effective words) took 4.4s, 1198102 effective words/s\n",
      "2020-08-24 02:32:20,652 : INFO : EPOCH 10 - PROGRESS: at 21.73% examples, 1139557 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:21,654 : INFO : EPOCH 10 - PROGRESS: at 44.53% examples, 1166703 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:22,656 : INFO : EPOCH 10 - PROGRESS: at 66.67% examples, 1165142 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-24 02:32:23,657 : INFO : EPOCH 10 - PROGRESS: at 87.87% examples, 1151647 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:24,197 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:24,208 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:24,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:24,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:24,214 : INFO : EPOCH - 10 : training on 7435641 raw words (5251068 effective words) took 4.6s, 1150984 effective words/s\n",
      "2020-08-24 02:32:25,219 : INFO : EPOCH 11 - PROGRESS: at 18.13% examples, 948601 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:26,224 : INFO : EPOCH 11 - PROGRESS: at 30.13% examples, 786974 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:27,229 : INFO : EPOCH 11 - PROGRESS: at 42.93% examples, 747800 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:28,239 : INFO : EPOCH 11 - PROGRESS: at 60.53% examples, 789870 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:29,241 : INFO : EPOCH 11 - PROGRESS: at 84.40% examples, 881713 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:29,904 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:29,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:29,922 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:29,928 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:29,929 : INFO : EPOCH - 11 : training on 7435641 raw words (5249628 effective words) took 5.7s, 918806 effective words/s\n",
      "2020-08-24 02:32:30,938 : INFO : EPOCH 12 - PROGRESS: at 22.53% examples, 1177078 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:31,940 : INFO : EPOCH 12 - PROGRESS: at 45.60% examples, 1193064 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:32,944 : INFO : EPOCH 12 - PROGRESS: at 68.13% examples, 1187849 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:33,945 : INFO : EPOCH 12 - PROGRESS: at 91.07% examples, 1191684 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:34,340 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:34,349 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:34,355 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:34,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:34,359 : INFO : EPOCH - 12 : training on 7435641 raw words (5251253 effective words) took 4.4s, 1186205 effective words/s\n",
      "2020-08-24 02:32:35,363 : INFO : EPOCH 13 - PROGRESS: at 22.00% examples, 1153121 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-24 02:32:36,365 : INFO : EPOCH 13 - PROGRESS: at 34.53% examples, 904335 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:37,373 : INFO : EPOCH 13 - PROGRESS: at 47.73% examples, 832017 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:38,386 : INFO : EPOCH 13 - PROGRESS: at 62.27% examples, 812210 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:39,391 : INFO : EPOCH 13 - PROGRESS: at 86.67% examples, 904671 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:39,951 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:39,955 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:39,960 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:39,961 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:39,962 : INFO : EPOCH - 13 : training on 7435641 raw words (5249794 effective words) took 5.6s, 937349 effective words/s\n",
      "2020-08-24 02:32:40,968 : INFO : EPOCH 14 - PROGRESS: at 24.13% examples, 1262481 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:41,968 : INFO : EPOCH 14 - PROGRESS: at 46.80% examples, 1226815 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:42,977 : INFO : EPOCH 14 - PROGRESS: at 69.87% examples, 1217764 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:43,994 : INFO : EPOCH 14 - PROGRESS: at 90.53% examples, 1179591 words/s, in_qsize 8, out_qsize 1\n",
      "2020-08-24 02:32:44,636 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:44,648 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:44,662 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:44,666 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:44,667 : INFO : EPOCH - 14 : training on 7435641 raw words (5250743 effective words) took 4.7s, 1116588 effective words/s\n",
      "2020-08-24 02:32:45,689 : INFO : EPOCH 15 - PROGRESS: at 13.33% examples, 688141 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:46,698 : INFO : EPOCH 15 - PROGRESS: at 27.20% examples, 704461 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:47,706 : INFO : EPOCH 15 - PROGRESS: at 50.40% examples, 872066 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:48,707 : INFO : EPOCH 15 - PROGRESS: at 74.27% examples, 965887 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:49,708 : INFO : EPOCH 15 - PROGRESS: at 97.73% examples, 1018676 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:49,791 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:49,793 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:49,810 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:49,811 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:49,812 : INFO : EPOCH - 15 : training on 7435641 raw words (5249958 effective words) took 5.1s, 1021354 effective words/s\n",
      "2020-08-24 02:32:50,815 : INFO : EPOCH 16 - PROGRESS: at 22.53% examples, 1180961 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:51,819 : INFO : EPOCH 16 - PROGRESS: at 45.33% examples, 1186635 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:52,831 : INFO : EPOCH 16 - PROGRESS: at 58.13% examples, 1011226 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:53,843 : INFO : EPOCH 16 - PROGRESS: at 70.40% examples, 917154 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-24 02:32:54,845 : INFO : EPOCH 16 - PROGRESS: at 83.20% examples, 868456 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-24 02:32:55,517 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:55,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:55,527 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:55,533 : INFO : worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-24 02:32:55,533 : INFO : EPOCH - 16 : training on 7435641 raw words (5251264 effective words) took 5.7s, 918173 effective words/s\n",
      "2020-08-24 02:32:56,537 : INFO : EPOCH 17 - PROGRESS: at 22.53% examples, 1180271 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:57,538 : INFO : EPOCH 17 - PROGRESS: at 46.53% examples, 1218530 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:58,546 : INFO : EPOCH 17 - PROGRESS: at 70.67% examples, 1231328 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:59,552 : INFO : EPOCH 17 - PROGRESS: at 93.87% examples, 1226001 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:32:59,832 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:32:59,844 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:32:59,861 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:32:59,863 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:32:59,864 : INFO : EPOCH - 17 : training on 7435641 raw words (5248102 effective words) took 4.3s, 1212274 effective words/s\n",
      "2020-08-24 02:33:00,872 : INFO : EPOCH 18 - PROGRESS: at 12.00% examples, 628184 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:01,875 : INFO : EPOCH 18 - PROGRESS: at 24.13% examples, 631581 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:02,890 : INFO : EPOCH 18 - PROGRESS: at 36.53% examples, 634843 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:03,893 : INFO : EPOCH 18 - PROGRESS: at 59.33% examples, 773930 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:04,895 : INFO : EPOCH 18 - PROGRESS: at 83.33% examples, 870359 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:05,590 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:33:05,591 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:33:05,594 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:33:05,599 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:33:05,600 : INFO : EPOCH - 18 : training on 7435641 raw words (5249732 effective words) took 5.7s, 916050 effective words/s\n",
      "2020-08-24 02:33:06,605 : INFO : EPOCH 19 - PROGRESS: at 22.13% examples, 1158259 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:07,607 : INFO : EPOCH 19 - PROGRESS: at 45.33% examples, 1186927 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:08,611 : INFO : EPOCH 19 - PROGRESS: at 58.80% examples, 1026089 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:09,615 : INFO : EPOCH 19 - PROGRESS: at 72.27% examples, 945547 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:10,625 : INFO : EPOCH 19 - PROGRESS: at 85.73% examples, 896221 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:11,310 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:33:11,317 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:33:11,318 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:33:11,329 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:33:11,330 : INFO : EPOCH - 19 : training on 7435641 raw words (5251343 effective words) took 5.7s, 916906 effective words/s\n",
      "2020-08-24 02:33:12,334 : INFO : EPOCH 20 - PROGRESS: at 24.00% examples, 1258034 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:13,344 : INFO : EPOCH 20 - PROGRESS: at 48.27% examples, 1259816 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:14,347 : INFO : EPOCH 20 - PROGRESS: at 71.60% examples, 1246892 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:15,350 : INFO : EPOCH 20 - PROGRESS: at 94.27% examples, 1232005 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-24 02:33:15,813 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-24 02:33:15,821 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-24 02:33:15,838 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-24 02:33:15,843 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-24 02:33:15,845 : INFO : EPOCH - 20 : training on 7435641 raw words (5251090 effective words) took 4.5s, 1163679 effective words/s\n",
      "2020-08-24 02:33:15,847 : INFO : training on a 148712820 raw words (105001898 effective words) took 93.6s, 1121850 effective words/s\n",
      "2020-08-24 02:33:15,848 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "##form the word2vec model with the training set which will be\n",
    "##used in the following two methods:\n",
    "##vector averaging and vector clustering of stop words\n",
    "model = form_model_from_sentences(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('queen', 0.3741656541824341), ('saxon', 0.31361255049705505), ('throne', 0.3131310045719147), ('conqueror', 0.31052806973457336), ('earl', 0.29378655552864075), ('girl', 0.28226879239082336), ('child', 0.2698107063770294), ('dying', 0.26731109619140625), ('reign', 0.26275989413261414), ('pillow', 0.2603800594806671)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-e2296c31c599>:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  print(model.most_similar(positive=['king', 'woman'], negative=['man']))\n"
     ]
    }
   ],
   "source": [
    "##check the model\n",
    "# king - man + woman = queen?\n",
    "print(model.most_similar(positive=['king', 'woman'], negative=['man']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('worse', 0.3971032500267029), ('wiser', 0.37148696184158325), ('sooner', 0.35369372367858887), ('happier', 0.3022949993610382), ('easier', 0.27671748399734497), ('fairer', 0.26694223284721375), ('bigger', 0.2663915753364563), ('safer', 0.2650602161884308), ('apprehended', 0.2614726722240448), ('dearer', 0.2573417127132416)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-2a4fea38c5af>:3: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  print(model.most_similar(positive=['better', 'bad'], negative=['good']))\n"
     ]
    }
   ],
   "source": [
    "##check the model\n",
    "# king - man + woman = queen?\n",
    "print(model.most_similar(positive=['better', 'bad'], negative=['good']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************\n",
    "##first method: vector averaging of stop words:\n",
    "import gensim\n",
    "all_stopwords = set(gensim.parsing.preprocessing.STOPWORDS)\n",
    "\n",
    "#be careful: nword and counter must be integers --Chiu\n",
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph which are stop words\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    index2word_set2 = all_stopwords\n",
    "    #\n",
    "    # Loop over each word in the text and, if it is in the model's\n",
    "    # vocaublary and is a stop word add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set: #and word in index2word_set2: \n",
    "            if word in index2word_set2:\n",
    "                nwords = nwords + 1\n",
    "                featureVec = np.add(featureVec, model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    if nwords == 0:\n",
    "        nwords = 1 #avoid devided by zero (i.e. no stop word)\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAvgFeatureVecs(texts, model, num_features):\n",
    "    # Given a set of texts (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    textFeatureVecs = np.zeros((len(texts),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the texts\n",
    "    for text in texts:\n",
    "       #\n",
    "       # Print a status message every 100th text\n",
    "        if counter%100 == 0:\n",
    "            haha = counter; hihi = len(texts)\n",
    "            print(f\"Text {haha} of {hihi}\") #% (counter, len(texts))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "        #textFeatureVecs[counter] = makeFeatureVec(text, model, num_features)\n",
    "        textFeatureVecs[counter] = makeFeatureVec(text, model, num_features)\n",
    "       # Increment the counter\n",
    "        counter = counter + 1\n",
    "    return textFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 0 of 7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-17-7a901c89f86d>:29: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  featureVec = np.add(featureVec, model[word])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 100 of 7500\n",
      "Text 200 of 7500\n",
      "Text 300 of 7500\n",
      "Text 400 of 7500\n",
      "Text 500 of 7500\n",
      "Text 600 of 7500\n",
      "Text 700 of 7500\n",
      "Text 800 of 7500\n",
      "Text 900 of 7500\n",
      "Text 1000 of 7500\n",
      "Text 1100 of 7500\n",
      "Text 1200 of 7500\n",
      "Text 1300 of 7500\n",
      "Text 1400 of 7500\n",
      "Text 1500 of 7500\n",
      "Text 1600 of 7500\n",
      "Text 1700 of 7500\n",
      "Text 1800 of 7500\n",
      "Text 1900 of 7500\n",
      "Text 2000 of 7500\n",
      "Text 2100 of 7500\n",
      "Text 2200 of 7500\n",
      "Text 2300 of 7500\n",
      "Text 2400 of 7500\n",
      "Text 2500 of 7500\n",
      "Text 2600 of 7500\n",
      "Text 2700 of 7500\n",
      "Text 2800 of 7500\n",
      "Text 2900 of 7500\n",
      "Text 3000 of 7500\n",
      "Text 3100 of 7500\n",
      "Text 3200 of 7500\n",
      "Text 3300 of 7500\n",
      "Text 3400 of 7500\n",
      "Text 3500 of 7500\n",
      "Text 3600 of 7500\n",
      "Text 3700 of 7500\n",
      "Text 3800 of 7500\n",
      "Text 3900 of 7500\n",
      "Text 4000 of 7500\n",
      "Text 4100 of 7500\n",
      "Text 4200 of 7500\n",
      "Text 4300 of 7500\n",
      "Text 4400 of 7500\n",
      "Text 4500 of 7500\n",
      "Text 4600 of 7500\n",
      "Text 4700 of 7500\n",
      "Text 4800 of 7500\n",
      "Text 4900 of 7500\n",
      "Text 5000 of 7500\n",
      "Text 5100 of 7500\n",
      "Text 5200 of 7500\n",
      "Text 5300 of 7500\n",
      "Text 5400 of 7500\n",
      "Text 5500 of 7500\n",
      "Text 5600 of 7500\n",
      "Text 5700 of 7500\n",
      "Text 5800 of 7500\n",
      "Text 5900 of 7500\n",
      "Text 6000 of 7500\n",
      "Text 6100 of 7500\n",
      "Text 6200 of 7500\n",
      "Text 6300 of 7500\n",
      "Text 6400 of 7500\n",
      "Text 6500 of 7500\n",
      "Text 6600 of 7500\n",
      "Text 6700 of 7500\n",
      "Text 6800 of 7500\n",
      "Text 6900 of 7500\n",
      "Text 7000 of 7500\n",
      "Text 7100 of 7500\n",
      "Text 7200 of 7500\n",
      "Text 7300 of 7500\n",
      "Text 7400 of 7500\n",
      "Creating average feature vecs for test texts\n",
      "Text 0 of 60\n",
      "Fitting a random forest to labeled training data...\n"
     ]
    }
   ],
   "source": [
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. \n",
    "\n",
    "clean_train_texts = []\n",
    "for text in train[\"text\"]:\n",
    "    #clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        #remove_stopwords=True )) #do not remove stop words\n",
    "    clean_train_texts.append( text_to_wordlist( text ))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_texts, model, num_features )\n",
    "\n",
    "print(\"Creating average feature vecs for test texts\")\n",
    "clean_test_texts = []\n",
    "for text in test[\"text\"]:\n",
    "    #clean_test_texts.append( text_to_wordlist( review, remove_stopwords=True ))\n",
    "    clean_test_texts.append( text_to_wordlist( text ))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_texts, model, num_features )\n",
    "\n",
    "# Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n",
    "\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit( trainDataVecs, train[\"author\"] )\n",
    "\n",
    "# Test & extract results \n",
    "result = forest.predict( testDataVecs )\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame( data={\"true_author\":test[\"author\"], \"pred_author\":result} )\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " Predicted  8   14  26\n",
      "Actural              \n",
      "8          18   2   0\n",
      "14          2  18   0\n",
      "26          0   0  20\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(output['true_author'], output['pred_author'], rownames=['Actural'], colnames=['Predicted'])\n",
    "print('Confusion matrix:\\n', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Accuracy: ', metrics.accuracy_score(output['true_author'], output['pred_author']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "print('f1 score: ', metrics.f1_score(output['true_author'], output['pred_author'], average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-9091e8a1385b>:11: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  word_vectors = model.wv.syn0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  527.5698883533478 seconds.\n",
      "\n",
      "Cluster 0\n",
      "['stroke', 'ripe', 'tain', 'shaggy', 'comb', 'growling', 'brim', 'skull', 'goat']\n",
      "\n",
      "Cluster 1\n",
      "['divine', 'demon', 'eternal', 'salvation', 'pathos', 'symbol']\n",
      "\n",
      "Cluster 2\n",
      "['pain', 'pity', 'secret', 'parting', 'shame', 'shock', 'horrible', 'pang']\n",
      "\n",
      "Cluster 3\n",
      "['bv', 'ana', 'wan', 'til', 'rf', 'fu', 'ally', 'tp', 'arid', 'sow', 'js', 'bait']\n",
      "\n",
      "Cluster 4\n",
      "['stone', 'prison', 'walls', 'pictures', 'size', 'wheels', 'rainbow', 'maps']\n",
      "\n",
      "Cluster 5\n",
      "['numbers', 'majority']\n",
      "\n",
      "Cluster 6\n",
      "['restored', 'reduced']\n",
      "\n",
      "Cluster 7\n",
      "['interesting', 'inferior', 'amusing', 'musical', 'unsatisfactory']\n",
      "\n",
      "Cluster 8\n",
      "['hers', 'faults', 'champion']\n",
      "\n",
      "Cluster 9\n",
      "['reach', 'pointed', 'stretch', 'stretching', 'shaped', 'lays', 'carries', 'tracing', 'stretches', 'straightened']\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "##second method: vector clustering of stop words (use KMeans):\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time (several to tens of minutes)\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.wv.syn0\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = int(num_clusters) )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Time taken for K Means clustering: \", elapsed, \"seconds.\")\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "#a cluster number\n",
    "\n",
    "word_centroid_map = dict(zip( model.wv.index2word, idx ))\n",
    "\n",
    "# For the first 10 clusters\n",
    "for cluster in range(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    #print \"\\nCluster %d\" #% cluster\n",
    "    print(f\"\\nCluster {cluster}\")\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    a_view = word_centroid_map.items()\n",
    "    tuples = list(a_view)\n",
    "    words = []\n",
    "    for i in range(0,len(word_centroid_map.values())):\n",
    "        if( tuples[i][1] == cluster ):\n",
    "            words.append(tuples[i][0])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map and word in all_stopwords:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros( (train[\"text\"].size, int(num_clusters)),     dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for text in clean_train_texts:\n",
    "    train_centroids[counter] = create_bag_of_centroids( text,         word_centroid_map )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "test_centroids = np.zeros((test[\"text\"].size, int(num_clusters)),     dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for text in clean_test_texts:\n",
    "    test_centroids[counter] = create_bag_of_centroids( text,         word_centroid_map )\n",
    "    counter += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n"
     ]
    }
   ],
   "source": [
    "# This cell take some minutes\n",
    "# Fit a random forest and extract predictions \n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fitting the forest may take a few minutes\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit(train_centroids,train[\"author\"])\n",
    "result = forest.predict(test_centroids)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"true_author\":test[\"author\"], \"pred_author\":result})\n",
    "output.to_csv( \"BagOfCentroidsAuthor.csv\", index=False, quoting=3 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " Predicted  8   14  26\n",
      "Actural              \n",
      "8          19   1   0\n",
      "14          1  19   0\n",
      "26          0   0  20\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(output['true_author'], output['pred_author'], rownames=['Actural'], colnames=['Predicted'])\n",
    "print('Confusion matrix:\\n', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('Accuracy: ', metrics.accuracy_score(output['true_author'], output['pred_author']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print('f1 score: ', metrics.f1_score(output['true_author'], output['pred_author'], average = 'weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
