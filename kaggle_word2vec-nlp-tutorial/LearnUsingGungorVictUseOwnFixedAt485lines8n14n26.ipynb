{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pathToGungorVict = '..//..//DS7004//u1720146_DS7004_courseworkCodeAndData//preparationWorks//fromDS7003_Gungor2018VictorianAuthorAttribution_NGram//Gungor_2018_VictorianAuthorAttribution_data-train.csv'\n",
    "gungorVictRow = pd.read_csv(pathToGungorVict, encoding = 'ISO-8859-1')\n",
    "#8 Charles Dickens 6914/ 14 George Eliot 2696/ 26 Jane Austen 4441"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "authorsLines = gungorVictRow.loc[gungorVictRow['author'] == 14] #the minimum: 2696 lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2696, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorsLines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in [26, 8]:\n",
    "    lines2696 = gungorVictRow.loc[gungorVictRow['author'] == i]\n",
    "    lines2696 = lines2696.iloc[0:2696]\n",
    "    authorsLines = authorsLines.append(lines2696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    author\n",
       "26    2696\n",
       "14    2696\n",
       "8     2696"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(authorsLines.author.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test = authorsLines.sample(frac=0.3, random_state=42)\n",
    "\n",
    "train = authorsLines.drop(test.index)\n",
    "train = train.sample(frac=1, random_state=42).reset_index()\n",
    "test = test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=2426, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=5662, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5503</td>\n",
       "      <td>deal of wine was drunk and everybody talked an...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15303</td>\n",
       "      <td>at and had more people o love than many a smal...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4672</td>\n",
       "      <td>was on fire and to be consulted in reference t...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26841</td>\n",
       "      <td>triumph and pursued her purpose careless of an...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4674</td>\n",
       "      <td>old house they live with us now they said i of...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>28076</td>\n",
       "      <td>mean â that he should have attached himself to...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>14468</td>\n",
       "      <td>make me do nothing you can t said bob yes i ca...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>16071</td>\n",
       "      <td>ht his less accurate grandmother poetry has al...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>27547</td>\n",
       "      <td>man might represent the county with such an es...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>14742</td>\n",
       "      <td>your pocket to think you ve got a better start...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2426 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text  author\n",
       "0      5503  deal of wine was drunk and everybody talked an...       8\n",
       "1     15303  at and had more people o love than many a smal...      14\n",
       "2      4672  was on fire and to be consulted in reference t...       8\n",
       "3     26841  triumph and pursued her purpose careless of an...      26\n",
       "4      4674  old house they live with us now they said i of...       8\n",
       "...     ...                                                ...     ...\n",
       "2421  28076  mean â that he should have attached himself to...      26\n",
       "2422  14468  make me do nothing you can t said bob yes i ca...      14\n",
       "2423  16071  ht his less accurate grandmother poetry has al...      14\n",
       "2424  27547  man might represent the county with such an es...      26\n",
       "2425  14742  your pocket to think you ve got a better start...      14\n",
       "\n",
       "[2426 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5784</td>\n",
       "      <td>misfortune to have an uncle who died leaving h...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5327</td>\n",
       "      <td>this does you credit twenty eight returned the...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29275</td>\n",
       "      <td>time to avoid to hear her young companion excl...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15859</td>\n",
       "      <td>her an we begun to be frightened and could n t...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27851</td>\n",
       "      <td>a winding t believed herself at last within re...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>3426</td>\n",
       "      <td>she was always very secret in her ways let me ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5658</th>\n",
       "      <td>5441</td>\n",
       "      <td>james who looked very for he was cleaning the ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5659</th>\n",
       "      <td>5483</td>\n",
       "      <td>fire and upset the tea and make all sorts of n...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5660</th>\n",
       "      <td>5721</td>\n",
       "      <td>shame em with her good looks yet ha ha she ii ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5661</th>\n",
       "      <td>14929</td>\n",
       "      <td>which had been contemporary with the successiv...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5662 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index                                               text  author\n",
       "0      5784  misfortune to have an uncle who died leaving h...       8\n",
       "1      5327  this does you credit twenty eight returned the...       8\n",
       "2     29275  time to avoid to hear her young companion excl...      26\n",
       "3     15859  her an we begun to be frightened and could n t...      14\n",
       "4     27851  a winding t believed herself at last within re...      26\n",
       "...     ...                                                ...     ...\n",
       "5657   3426  she was always very secret in her ways let me ...       8\n",
       "5658   5441  james who looked very for he was cleaning the ...       8\n",
       "5659   5483  fire and upset the tea and make all sorts of n...       8\n",
       "5660   5721  shame em with her good looks yet ha ha she ii ...       8\n",
       "5661  14929  which had been contemporary with the successiv...      14\n",
       "\n",
       "[5662 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download the punkt tokenizer for sentence splitting\n",
    "import nltk.data\n",
    "#nltk.download() no need to use this line after using it once(?)   \n",
    "\n",
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define a function to split a review into parsed sentences\n",
    "def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "    # Function to split a review into parsed sentences. Returns a \n",
    "    # list of sentences, where each sentence is a list of words\n",
    "    #\n",
    "    # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "    raw_sentences = tokenizer.tokenize(review.strip())\n",
    "    #\n",
    "    # 2. Loop over each sentence\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        # If a sentence is empty, skip it\n",
    "        if len(raw_sentence) > 0:\n",
    "            # Otherwise, call review_to_wordlist to get a list of words\n",
    "            sentences.append( review_to_wordlist( raw_sentence, \\\n",
    "              remove_stopwords ))\n",
    "    #\n",
    "    # Return the list of sentences (each sentence is a list of words,\n",
    "    # so this returns a list of lists\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def parsing_sentence_set(text_df):\n",
    "    sentences = []  # Initialize an empty list of sentences\n",
    "\n",
    "    print(\"Parsing sentences from training set\")\n",
    "    for review in text_df[\"text\"]:\n",
    "        sentences += review_to_sentences(review, tokenizer)\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from training set\n"
     ]
    }
   ],
   "source": [
    "authors_sentences = parsing_sentence_set(authorsLines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8088\n"
     ]
    }
   ],
   "source": [
    "print(len(authors_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import the built-in logging module and configure it so that Word2Vec \n",
    "# creates nice output messages\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "#num_features = 300    # Word vector dimensionality                      \n",
    "#min_word_count = 40   # Minimum word count                        \n",
    "#num_workers = 4       # Number of threads to run in parallel\n",
    "#context = 10          # Context window size                                                                                    \n",
    "#downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "num_features = 300    # Word vector dimensionality                      \n",
    "min_word_count = 5    # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 5           # Context window size                                                                                    \n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "epochs=15             #number of epochs\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "def form_model_from_sentences(sentences):\n",
    "    print(\"Training model...\")\n",
    "    model = word2vec.Word2Vec(sentences, workers=num_workers, \\\n",
    "                size=num_features, min_count = min_word_count, \\\n",
    "                window = context, sample = downsampling, iter = epochs)\n",
    "\n",
    "    # If you don't plan to train the model any further, calling \n",
    "    # init_sims will make the model much more memory-efficient.\n",
    "    model.init_sims(replace=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-22 13:04:43,100 : INFO : collecting all words and their counts\n",
      "2020-08-22 13:04:43,102 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-22 13:04:44,371 : INFO : collected 9976 word types from a corpus of 8019053 raw words and 8088 sentences\n",
      "2020-08-22 13:04:44,372 : INFO : Loading a fresh vocabulary\n",
      "2020-08-22 13:04:44,509 : INFO : effective_min_count=5 retains 9956 unique words (99% of original 9976, drops 20)\n",
      "2020-08-22 13:04:44,510 : INFO : effective_min_count=5 leaves 8018990 word corpus (99% of original 8019053, drops 63)\n",
      "2020-08-22 13:04:44,537 : INFO : deleting the raw counts dictionary of 9976 items\n",
      "2020-08-22 13:04:44,539 : INFO : sample=0.001 downsamples 55 most-common words\n",
      "2020-08-22 13:04:44,540 : INFO : downsampling leaves estimated 5665155 word corpus (70.6% of prior 8018990)\n",
      "2020-08-22 13:04:44,574 : INFO : estimated required memory for 9956 words and 300 dimensions: 28872400 bytes\n",
      "2020-08-22 13:04:44,575 : INFO : resetting layer weights\n",
      "2020-08-22 13:04:46,254 : INFO : training model with 4 workers on 9956 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-08-22 13:04:47,263 : INFO : EPOCH 1 - PROGRESS: at 17.31% examples, 976884 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:48,263 : INFO : EPOCH 1 - PROGRESS: at 40.18% examples, 1138203 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:49,268 : INFO : EPOCH 1 - PROGRESS: at 65.65% examples, 1239711 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:50,275 : INFO : EPOCH 1 - PROGRESS: at 91.00% examples, 1284617 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:50,639 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:04:50,646 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:04:50,648 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:04:50,649 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:04:50,650 : INFO : EPOCH - 1 : training on 8019053 raw words (5664817 effective words) took 4.4s, 1291331 effective words/s\n",
      "2020-08-22 13:04:51,653 : INFO : EPOCH 2 - PROGRESS: at 20.52% examples, 1158168 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:52,656 : INFO : EPOCH 2 - PROGRESS: at 44.88% examples, 1269660 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:53,662 : INFO : EPOCH 2 - PROGRESS: at 67.63% examples, 1275015 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:54,663 : INFO : EPOCH 2 - PROGRESS: at 92.73% examples, 1309483 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:54,941 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:04:54,945 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:04:54,948 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:04:54,949 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:04:54,949 : INFO : EPOCH - 2 : training on 8019053 raw words (5664425 effective words) took 4.3s, 1318064 effective words/s\n",
      "2020-08-22 13:04:55,959 : INFO : EPOCH 3 - PROGRESS: at 22.87% examples, 1285051 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:56,962 : INFO : EPOCH 3 - PROGRESS: at 46.36% examples, 1306900 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:57,962 : INFO : EPOCH 3 - PROGRESS: at 70.10% examples, 1320855 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:58,964 : INFO : EPOCH 3 - PROGRESS: at 88.16% examples, 1244632 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:04:59,591 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:04:59,605 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:04:59,606 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:04:59,612 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:04:59,613 : INFO : EPOCH - 3 : training on 8019053 raw words (5663765 effective words) took 4.7s, 1215444 effective words/s\n",
      "2020-08-22 13:05:00,622 : INFO : EPOCH 4 - PROGRESS: at 18.30% examples, 1026678 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:01,628 : INFO : EPOCH 4 - PROGRESS: at 34.00% examples, 957572 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:02,631 : INFO : EPOCH 4 - PROGRESS: at 55.64% examples, 1046270 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:03,635 : INFO : EPOCH 4 - PROGRESS: at 79.50% examples, 1121520 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:04,526 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:04,529 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:04,532 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:04,534 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:04,535 : INFO : EPOCH - 4 : training on 8019053 raw words (5665489 effective words) took 4.9s, 1151804 effective words/s\n",
      "2020-08-22 13:05:05,552 : INFO : EPOCH 5 - PROGRESS: at 22.38% examples, 1248385 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:06,553 : INFO : EPOCH 5 - PROGRESS: at 45.13% examples, 1269047 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:07,555 : INFO : EPOCH 5 - PROGRESS: at 68.74% examples, 1292965 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:08,557 : INFO : EPOCH 5 - PROGRESS: at 91.62% examples, 1291215 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:08,946 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:08,947 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:08,948 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:08,958 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:08,959 : INFO : EPOCH - 5 : training on 8019053 raw words (5665419 effective words) took 4.4s, 1281480 effective words/s\n",
      "2020-08-22 13:05:09,961 : INFO : EPOCH 6 - PROGRESS: at 21.51% examples, 1215537 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:10,964 : INFO : EPOCH 6 - PROGRESS: at 44.51% examples, 1259276 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:11,966 : INFO : EPOCH 6 - PROGRESS: at 66.02% examples, 1246323 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:12,969 : INFO : EPOCH 6 - PROGRESS: at 87.78% examples, 1240468 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:13,496 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:13,511 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:13,515 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:13,515 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:13,516 : INFO : EPOCH - 6 : training on 8019053 raw words (5665621 effective words) took 4.6s, 1243781 effective words/s\n",
      "2020-08-22 13:05:14,521 : INFO : EPOCH 7 - PROGRESS: at 16.82% examples, 947568 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:15,522 : INFO : EPOCH 7 - PROGRESS: at 34.25% examples, 968954 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:16,554 : INFO : EPOCH 7 - PROGRESS: at 48.59% examples, 908056 words/s, in_qsize 7, out_qsize 2\n",
      "2020-08-22 13:05:17,558 : INFO : EPOCH 7 - PROGRESS: at 65.41% examples, 918827 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:18,563 : INFO : EPOCH 7 - PROGRESS: at 85.44% examples, 960036 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:19,266 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:19,269 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:19,275 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:19,279 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:19,280 : INFO : EPOCH - 7 : training on 8019053 raw words (5665424 effective words) took 5.8s, 983531 effective words/s\n",
      "2020-08-22 13:05:20,291 : INFO : EPOCH 8 - PROGRESS: at 19.54% examples, 1093659 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:21,293 : INFO : EPOCH 8 - PROGRESS: at 39.44% examples, 1110722 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:22,296 : INFO : EPOCH 8 - PROGRESS: at 59.97% examples, 1128593 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:23,300 : INFO : EPOCH 8 - PROGRESS: at 80.49% examples, 1135814 words/s, in_qsize 7, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-22 13:05:24,229 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:24,232 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:24,243 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:24,248 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:24,249 : INFO : EPOCH - 8 : training on 8019053 raw words (5665294 effective words) took 5.0s, 1140879 effective words/s\n",
      "2020-08-22 13:05:25,255 : INFO : EPOCH 9 - PROGRESS: at 19.41% examples, 1091098 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:26,272 : INFO : EPOCH 9 - PROGRESS: at 38.33% examples, 1073493 words/s, in_qsize 8, out_qsize 1\n",
      "2020-08-22 13:05:27,272 : INFO : EPOCH 9 - PROGRESS: at 49.70% examples, 932576 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:28,278 : INFO : EPOCH 9 - PROGRESS: at 61.70% examples, 868969 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:29,287 : INFO : EPOCH 9 - PROGRESS: at 77.03% examples, 867402 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:30,294 : INFO : EPOCH 9 - PROGRESS: at 98.05% examples, 918994 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:30,376 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:30,379 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:30,383 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:30,385 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:30,386 : INFO : EPOCH - 9 : training on 8019053 raw words (5665831 effective words) took 6.1s, 923388 effective words/s\n",
      "2020-08-22 13:05:31,390 : INFO : EPOCH 10 - PROGRESS: at 21.14% examples, 1193313 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:32,399 : INFO : EPOCH 10 - PROGRESS: at 41.91% examples, 1181578 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:33,409 : INFO : EPOCH 10 - PROGRESS: at 63.43% examples, 1191715 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:34,416 : INFO : EPOCH 10 - PROGRESS: at 81.60% examples, 1148843 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:35,315 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:35,316 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:35,320 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:35,330 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:35,331 : INFO : EPOCH - 10 : training on 8019053 raw words (5666456 effective words) took 4.9s, 1146406 effective words/s\n",
      "2020-08-22 13:05:36,339 : INFO : EPOCH 11 - PROGRESS: at 19.41% examples, 1090288 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:37,339 : INFO : EPOCH 11 - PROGRESS: at 31.40% examples, 886337 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:38,342 : INFO : EPOCH 11 - PROGRESS: at 43.03% examples, 810362 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:39,343 : INFO : EPOCH 11 - PROGRESS: at 55.89% examples, 789888 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-22 13:05:40,351 : INFO : EPOCH 11 - PROGRESS: at 78.02% examples, 881505 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:41,351 : INFO : EPOCH 11 - PROGRESS: at 99.65% examples, 937976 words/s, in_qsize 3, out_qsize 1\n",
      "2020-08-22 13:05:41,352 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:41,356 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:41,358 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:41,358 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:41,359 : INFO : EPOCH - 11 : training on 8019053 raw words (5663875 effective words) took 6.0s, 940066 effective words/s\n",
      "2020-08-22 13:05:42,366 : INFO : EPOCH 12 - PROGRESS: at 21.76% examples, 1225872 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:43,370 : INFO : EPOCH 12 - PROGRESS: at 42.53% examples, 1200147 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:44,378 : INFO : EPOCH 12 - PROGRESS: at 63.06% examples, 1186253 words/s, in_qsize 8, out_qsize 0\n",
      "2020-08-22 13:05:45,383 : INFO : EPOCH 12 - PROGRESS: at 83.95% examples, 1183455 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:46,385 : INFO : EPOCH 12 - PROGRESS: at 96.32% examples, 1086243 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:46,666 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:46,686 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:46,700 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:46,702 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:46,704 : INFO : EPOCH - 12 : training on 8019053 raw words (5665844 effective words) took 5.3s, 1060677 effective words/s\n",
      "2020-08-22 13:05:47,711 : INFO : EPOCH 13 - PROGRESS: at 11.75% examples, 659344 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:48,716 : INFO : EPOCH 13 - PROGRESS: at 27.45% examples, 774209 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:49,722 : INFO : EPOCH 13 - PROGRESS: at 49.58% examples, 933250 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:50,729 : INFO : EPOCH 13 - PROGRESS: at 71.46% examples, 1008253 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:51,738 : INFO : EPOCH 13 - PROGRESS: at 93.35% examples, 1051557 words/s, in_qsize 7, out_qsize 1\n",
      "2020-08-22 13:05:52,022 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:52,026 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:52,038 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:52,039 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:52,040 : INFO : EPOCH - 13 : training on 8019053 raw words (5666570 effective words) took 5.3s, 1062859 effective words/s\n",
      "2020-08-22 13:05:53,049 : INFO : EPOCH 14 - PROGRESS: at 21.39% examples, 1200443 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:54,052 : INFO : EPOCH 14 - PROGRESS: at 38.70% examples, 1090292 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:55,057 : INFO : EPOCH 14 - PROGRESS: at 50.82% examples, 955911 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:56,065 : INFO : EPOCH 14 - PROGRESS: at 62.81% examples, 885727 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:57,067 : INFO : EPOCH 14 - PROGRESS: at 78.76% examples, 888580 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:05:58,012 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:05:58,022 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:05:58,029 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:05:58,031 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:05:58,031 : INFO : EPOCH - 14 : training on 8019053 raw words (5665252 effective words) took 6.0s, 945894 effective words/s\n",
      "2020-08-22 13:05:59,038 : INFO : EPOCH 15 - PROGRESS: at 22.26% examples, 1253397 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:06:00,039 : INFO : EPOCH 15 - PROGRESS: at 42.41% examples, 1198757 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:06:01,040 : INFO : EPOCH 15 - PROGRESS: at 62.93% examples, 1187138 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:06:02,045 : INFO : EPOCH 15 - PROGRESS: at 76.66% examples, 1083810 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:06:03,067 : INFO : EPOCH 15 - PROGRESS: at 88.90% examples, 1000179 words/s, in_qsize 7, out_qsize 0\n",
      "2020-08-22 13:06:04,016 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-08-22 13:06:04,018 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-08-22 13:06:04,024 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-08-22 13:06:04,029 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-08-22 13:06:04,031 : INFO : EPOCH - 15 : training on 8019053 raw words (5664307 effective words) took 6.0s, 944459 effective words/s\n",
      "2020-08-22 13:06:04,032 : INFO : training on a 120285795 raw words (84978389 effective words) took 77.8s, 1092594 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-08-22 13:06:04,033 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model = form_model_from_sentences(authors_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-95bb2fc5eda1>:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  model.most_similar(positive=['king', 'woman'], negative=['man'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('queen', 0.4187351167201996),\n",
       " ('earl', 0.40320053696632385),\n",
       " ('prince', 0.3588062822818756),\n",
       " ('conqueror', 0.34097394347190857),\n",
       " ('france', 0.3379788100719452),\n",
       " ('french', 0.33247894048690796),\n",
       " ('girl', 0.3150230050086975),\n",
       " ('throne', 0.3080468773841858),\n",
       " ('priests', 0.30735668540000916),\n",
       " ('richard', 0.30342161655426025)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(positive=['king', 'woman'], negative=['man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoungst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'bill',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'co',\n",
       " 'computer',\n",
       " 'con',\n",
       " 'could',\n",
       " 'couldnt',\n",
       " 'cry',\n",
       " 'de',\n",
       " 'describe',\n",
       " 'detail',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'doing',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'fill',\n",
       " 'find',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'found',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'had',\n",
       " 'has',\n",
       " 'hasnt',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'ie',\n",
       " 'if',\n",
       " 'in',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'interest',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'kg',\n",
       " 'km',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'ltd',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mill',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'sincere',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'system',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'thick',\n",
       " 'thin',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'would',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "all_stopwords = set(gensim.parsing.preprocessing.STOPWORDS)\n",
    "all_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#be careful: nword and counter must be integers --Chiu\n",
    "import numpy as np  # Make sure that numpy is imported\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Function to average all of the word vectors in a given\n",
    "    # paragraph\n",
    "    #\n",
    "    # Pre-initialize an empty numpy array (for speed)\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    #\n",
    "    nwords = 0\n",
    "    # \n",
    "    # Index2word is a list that contains the names of the words in \n",
    "    # the model's vocabulary. Convert it to a set, for speed \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    index2word_set2 = all_stopwords\n",
    "    #\n",
    "    # Loop over each word in the review and, if it is in the model's\n",
    "    # vocaublary, add its feature vector to the total\n",
    "    for word in words:\n",
    "        if word in index2word_set and word in index2word_set2: \n",
    "            nwords = nwords + 1\n",
    "            featureVec = np.add(featureVec,model[word])\n",
    "    # \n",
    "    # Divide the result by the number of words to get the average\n",
    "    if nwords == 0:\n",
    "        nwords = 1\n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "\n",
    "def getAvgFeatureVecs(reviews, model, num_features):\n",
    "    # Given a set of reviews (each one a list of words), calculate \n",
    "    # the average feature vector for each one and return a 2D numpy array \n",
    "    # \n",
    "    # Initialize a counter\n",
    "    counter = 0\n",
    "    # \n",
    "    # Preallocate a 2D numpy array, for speed\n",
    "    reviewFeatureVecs = np.zeros((len(reviews),num_features),dtype=\"float32\")\n",
    "    # \n",
    "    # Loop through the reviews\n",
    "    for review in reviews:\n",
    "       #\n",
    "       # Print a status message every 1000th review\n",
    "        if counter%50 == 0:\n",
    "            haha = counter; hihi = len(reviews)\n",
    "            print(f\"Review {haha} of {hihi}\") #% (counter, len(reviews))\n",
    "       # \n",
    "       # Call the function (defined above) that makes average feature vectors\n",
    "        #reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "        reviewFeatureVecs[counter] = makeFeatureVec(review, model, num_features)\n",
    "       #\n",
    "       # Increment the counter\n",
    "        counter = counter + 1\n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import various modules for string cleaning\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def review_to_wordlist( review, remove_stopwords=False ):\n",
    "    # Function to convert a document to a sequence of words,\n",
    "    # optionally removing stop words.  Returns a list of words.\n",
    "    #\n",
    "    # 1. Remove HTML\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    #  \n",
    "    # 2. Remove non-letters\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    #\n",
    "    # 3. Convert words to lower case and split them\n",
    "    words = review_text.lower().split()\n",
    "    #\n",
    "    # 4. Optionally remove stop words (false by default)\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "    #\n",
    "    # 5. Return a list of words\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 0 of 5662\n",
      "Review 50 of 5662\n",
      "Review 100 of 5662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-8856e0a8f420>:23: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  featureVec = np.add(featureVec,model[word])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 150 of 5662\n",
      "Review 200 of 5662\n",
      "Review 250 of 5662\n",
      "Review 300 of 5662\n",
      "Review 350 of 5662\n",
      "Review 400 of 5662\n",
      "Review 450 of 5662\n",
      "Review 500 of 5662\n",
      "Review 550 of 5662\n",
      "Review 600 of 5662\n",
      "Review 650 of 5662\n",
      "Review 700 of 5662\n",
      "Review 750 of 5662\n",
      "Review 800 of 5662\n",
      "Review 850 of 5662\n",
      "Review 900 of 5662\n",
      "Review 950 of 5662\n",
      "Review 1000 of 5662\n",
      "Review 1050 of 5662\n",
      "Review 1100 of 5662\n",
      "Review 1150 of 5662\n",
      "Review 1200 of 5662\n",
      "Review 1250 of 5662\n",
      "Review 1300 of 5662\n",
      "Review 1350 of 5662\n",
      "Review 1400 of 5662\n",
      "Review 1450 of 5662\n",
      "Review 1500 of 5662\n",
      "Review 1550 of 5662\n",
      "Review 1600 of 5662\n",
      "Review 1650 of 5662\n",
      "Review 1700 of 5662\n",
      "Review 1750 of 5662\n",
      "Review 1800 of 5662\n",
      "Review 1850 of 5662\n",
      "Review 1900 of 5662\n",
      "Review 1950 of 5662\n",
      "Review 2000 of 5662\n",
      "Review 2050 of 5662\n",
      "Review 2100 of 5662\n",
      "Review 2150 of 5662\n",
      "Review 2200 of 5662\n",
      "Review 2250 of 5662\n",
      "Review 2300 of 5662\n",
      "Review 2350 of 5662\n",
      "Review 2400 of 5662\n",
      "Review 2450 of 5662\n",
      "Review 2500 of 5662\n",
      "Review 2550 of 5662\n",
      "Review 2600 of 5662\n",
      "Review 2650 of 5662\n",
      "Review 2700 of 5662\n",
      "Review 2750 of 5662\n",
      "Review 2800 of 5662\n",
      "Review 2850 of 5662\n",
      "Review 2900 of 5662\n",
      "Review 2950 of 5662\n",
      "Review 3000 of 5662\n",
      "Review 3050 of 5662\n",
      "Review 3100 of 5662\n",
      "Review 3150 of 5662\n",
      "Review 3200 of 5662\n",
      "Review 3250 of 5662\n",
      "Review 3300 of 5662\n",
      "Review 3350 of 5662\n",
      "Review 3400 of 5662\n",
      "Review 3450 of 5662\n",
      "Review 3500 of 5662\n",
      "Review 3550 of 5662\n",
      "Review 3600 of 5662\n",
      "Review 3650 of 5662\n",
      "Review 3700 of 5662\n",
      "Review 3750 of 5662\n",
      "Review 3800 of 5662\n",
      "Review 3850 of 5662\n",
      "Review 3900 of 5662\n",
      "Review 3950 of 5662\n",
      "Review 4000 of 5662\n",
      "Review 4050 of 5662\n",
      "Review 4100 of 5662\n",
      "Review 4150 of 5662\n",
      "Review 4200 of 5662\n",
      "Review 4250 of 5662\n",
      "Review 4300 of 5662\n",
      "Review 4350 of 5662\n",
      "Review 4400 of 5662\n",
      "Review 4450 of 5662\n",
      "Review 4500 of 5662\n",
      "Review 4550 of 5662\n",
      "Review 4600 of 5662\n",
      "Review 4650 of 5662\n",
      "Review 4700 of 5662\n",
      "Review 4750 of 5662\n",
      "Review 4800 of 5662\n",
      "Review 4850 of 5662\n",
      "Review 4900 of 5662\n",
      "Review 4950 of 5662\n",
      "Review 5000 of 5662\n",
      "Review 5050 of 5662\n",
      "Review 5100 of 5662\n",
      "Review 5150 of 5662\n",
      "Review 5200 of 5662\n",
      "Review 5250 of 5662\n",
      "Review 5300 of 5662\n",
      "Review 5350 of 5662\n",
      "Review 5400 of 5662\n",
      "Review 5450 of 5662\n",
      "Review 5500 of 5662\n",
      "Review 5550 of 5662\n",
      "Review 5600 of 5662\n",
      "Review 5650 of 5662\n",
      "Creating average feature vecs for test reviews\n",
      "Review 0 of 2426\n",
      "Review 50 of 2426\n",
      "Review 100 of 2426\n",
      "Review 150 of 2426\n",
      "Review 200 of 2426\n",
      "Review 250 of 2426\n",
      "Review 300 of 2426\n",
      "Review 350 of 2426\n",
      "Review 400 of 2426\n",
      "Review 450 of 2426\n",
      "Review 500 of 2426\n",
      "Review 550 of 2426\n",
      "Review 600 of 2426\n",
      "Review 650 of 2426\n",
      "Review 700 of 2426\n",
      "Review 750 of 2426\n",
      "Review 800 of 2426\n",
      "Review 850 of 2426\n",
      "Review 900 of 2426\n",
      "Review 950 of 2426\n",
      "Review 1000 of 2426\n",
      "Review 1050 of 2426\n",
      "Review 1100 of 2426\n",
      "Review 1150 of 2426\n",
      "Review 1200 of 2426\n",
      "Review 1250 of 2426\n",
      "Review 1300 of 2426\n",
      "Review 1350 of 2426\n",
      "Review 1400 of 2426\n",
      "Review 1450 of 2426\n",
      "Review 1500 of 2426\n",
      "Review 1550 of 2426\n",
      "Review 1600 of 2426\n",
      "Review 1650 of 2426\n",
      "Review 1700 of 2426\n",
      "Review 1750 of 2426\n",
      "Review 1800 of 2426\n",
      "Review 1850 of 2426\n",
      "Review 1900 of 2426\n",
      "Review 1950 of 2426\n",
      "Review 2000 of 2426\n",
      "Review 2050 of 2426\n",
      "Review 2100 of 2426\n",
      "Review 2150 of 2426\n",
      "Review 2200 of 2426\n",
      "Review 2250 of 2426\n",
      "Review 2300 of 2426\n",
      "Review 2350 of 2426\n",
      "Review 2400 of 2426\n"
     ]
    }
   ],
   "source": [
    "# ****************************************************************\n",
    "# Calculate average feature vectors for training and testing sets,\n",
    "# using the functions we defined above. Notice that we now use stop word\n",
    "# removal.\n",
    "num_features = 300\n",
    "clean_train_reviews = []\n",
    "for review in train[\"text\"]:\n",
    "    #clean_train_reviews.append( review_to_wordlist( review, \\\n",
    "        #remove_stopwords=True ))\n",
    "    clean_train_reviews.append( review_to_wordlist( review ))\n",
    "\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_reviews, model, num_features )\n",
    "\n",
    "print(\"Creating average feature vecs for test reviews\")\n",
    "clean_test_reviews = []\n",
    "for review in test[\"text\"]:\n",
    "    #clean_test_reviews.append( review_to_wordlist( review, remove_stopwords=True ))\n",
    "    clean_test_reviews.append( review_to_wordlist( review ))\n",
    "\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_reviews, model, num_features )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n"
     ]
    }
   ],
   "source": [
    "# Fit a random forest to the training data, using 100 trees\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest = RandomForestClassifier( n_estimators = 100 )\n",
    "\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit( trainDataVecs, train[\"author\"] )\n",
    "\n",
    "# Test & extract results \n",
    "result = forest.predict( testDataVecs )\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame( data={\"true_author\":test[\"author\"], \"pred_author\":result} )\n",
    "output.to_csv( \"Word2Vec_AverageVectors.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      true_author  pred_author\n",
      "0               8            8\n",
      "1              14           14\n",
      "2               8            8\n",
      "3              26           26\n",
      "4               8            8\n",
      "...           ...          ...\n",
      "2421           26           26\n",
      "2422           14           14\n",
      "2423           14           14\n",
      "2424           26           26\n",
      "2425           14           14\n",
      "\n",
      "[2426 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   8    14   26\n",
      "Actural                 \n",
      "8          714   66    9\n",
      "14          76  717   55\n",
      "26          20   32  737\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(output['true_author'], output['pred_author'], rownames=['Actural'], colnames=['Predicted'])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[714,  66,   9],\n",
       "       [ 76, 717,  55],\n",
       "       [ 20,  32, 737]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.confusion_matrix(output['true_author'], output['pred_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.88148148, 0.8797546 , 0.92009988]),\n",
       " array([0.90494297, 0.84551887, 0.93409379]),\n",
       " array([0.89305816, 0.86229705, 0.92704403]),\n",
       " array([789, 848, 789], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_recall_fscore_support(output['true_author'], output['pred_author'], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    true_author\n",
       "14          848\n",
       "26          789\n",
       "8           789"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(output.true_author.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-98a1d4cbf9c6>:1: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  word_vectors = model.wv.syn0\n"
     ]
    }
   ],
   "source": [
    "word_vectors = model.wv.syn0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9956, 300)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-c310dcc16c02>:8: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.vectors instead).\n",
      "  word_vectors = model.wv.syn0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  496.34906005859375 seconds.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "word_vectors = model.wv.syn0\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = int(num_clusters) )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(\"Time taken for K Means clustering: \", elapsed, \"seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.wv.index2word, idx ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'descriptive'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(word_centroid_map, key=word_centroid_map.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_centroid_map.get('descriptive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'the': 1608,\n",
       "  'and': 289,\n",
       "  'to': 765,\n",
       "  'of': 730,\n",
       "  'a': 413,\n",
       "  'i': 910,\n",
       "  'in': 391,\n",
       "  'was': 1310,\n",
       "  'that': 443,\n",
       "  'her': 165,\n",
       "  'it': 962,\n",
       "  'he': 962,\n",
       "  'as': 1374,\n",
       "  'you': 910,\n",
       "  'she': 962,\n",
       "  'his': 277,\n",
       "  'with': 1716,\n",
       "  'had': 780,\n",
       "  'not': 671,\n",
       "  'for': 833,\n",
       "  'be': 808,\n",
       "  's': 154,\n",
       "  'but': 587,\n",
       "  'at': 1441,\n",
       "  'on': 391,\n",
       "  'have': 78,\n",
       "  'is': 1015,\n",
       "  'my': 154,\n",
       "  'by': 405,\n",
       "  'him': 865,\n",
       "  'said': 1475,\n",
       "  'me': 865,\n",
       "  'which': 1092,\n",
       "  'mr': 594,\n",
       "  'all': 974,\n",
       "  'so': 1374,\n",
       "  'this': 651,\n",
       "  'no': 464,\n",
       "  'from': 787,\n",
       "  'been': 1271,\n",
       "  'were': 662,\n",
       "  'would': 1385,\n",
       "  'if': 1130,\n",
       "  'an': 1690,\n",
       "  'there': 1593,\n",
       "  'what': 1632,\n",
       "  'when': 289,\n",
       "  't': 239,\n",
       "  'they': 317,\n",
       "  'could': 1385,\n",
       "  'or': 934,\n",
       "  'very': 191,\n",
       "  'one': 1960,\n",
       "  'more': 547,\n",
       "  'we': 61,\n",
       "  'who': 1223,\n",
       "  'do': 401,\n",
       "  'any': 464,\n",
       "  'will': 265,\n",
       "  'mrs': 594,\n",
       "  'are': 1936,\n",
       "  'them': 482,\n",
       "  'out': 156,\n",
       "  'than': 934,\n",
       "  'their': 1342,\n",
       "  'little': 681,\n",
       "  'your': 154,\n",
       "  'now': 910,\n",
       "  'up': 1008,\n",
       "  'some': 1798,\n",
       "  'am': 506,\n",
       "  'know': 401,\n",
       "  'much': 243,\n",
       "  'should': 1385,\n",
       "  'into': 156,\n",
       "  'must': 10,\n",
       "  'only': 1437,\n",
       "  'such': 1215,\n",
       "  'time': 1584,\n",
       "  'good': 1367,\n",
       "  'well': 589,\n",
       "  'about': 899,\n",
       "  'never': 671,\n",
       "  'like': 849,\n",
       "  'can': 265,\n",
       "  'own': 1047,\n",
       "  'before': 289,\n",
       "  'did': 1015,\n",
       "  'might': 1385,\n",
       "  'has': 780,\n",
       "  'think': 1971,\n",
       "  'man': 1737,\n",
       "  'miss': 594,\n",
       "  'being': 685,\n",
       "  'how': 1632,\n",
       "  'then': 289,\n",
       "  'other': 136,\n",
       "  'made': 781,\n",
       "  'see': 657,\n",
       "  'say': 46,\n",
       "  'again': 194,\n",
       "  'too': 191,\n",
       "  'after': 472,\n",
       "  'come': 89,\n",
       "  'every': 726,\n",
       "  'upon': 391,\n",
       "  'sir': 742,\n",
       "  'may': 10,\n",
       "  'old': 1343,\n",
       "  'two': 1259,\n",
       "  'without': 985,\n",
       "  'down': 156,\n",
       "  'great': 345,\n",
       "  'nothing': 749,\n",
       "  'first': 1401,\n",
       "  'himself': 865,\n",
       "  'day': 619,\n",
       "  'go': 89,\n",
       "  'thought': 1971,\n",
       "  'way': 1262,\n",
       "  'our': 1342,\n",
       "  'make': 781,\n",
       "  'here': 910,\n",
       "  'its': 1397,\n",
       "  'us': 482,\n",
       "  'away': 156,\n",
       "  'dear': 1779,\n",
       "  'most': 764,\n",
       "  'mother': 118,\n",
       "  'herself': 165,\n",
       "  'long': 62,\n",
       "  'over': 1592,\n",
       "  'where': 752,\n",
       "  'though': 986,\n",
       "  'ever': 671,\n",
       "  'thing': 509,\n",
       "  'life': 1235,\n",
       "  'quite': 621,\n",
       "  'room': 520,\n",
       "  'always': 1161,\n",
       "  'mind': 1005,\n",
       "  'house': 998,\n",
       "  'shall': 265,\n",
       "  'came': 1973,\n",
       "  'even': 1796,\n",
       "  'young': 1079,\n",
       "  'hand': 1853,\n",
       "  'last': 1401,\n",
       "  'm': 506,\n",
       "  'look': 112,\n",
       "  'went': 656,\n",
       "  'while': 1674,\n",
       "  'better': 763,\n",
       "  'take': 168,\n",
       "  'many': 279,\n",
       "  'lady': 344,\n",
       "  'felt': 1186,\n",
       "  'these': 1726,\n",
       "  'back': 128,\n",
       "  'don': 226,\n",
       "  'soon': 738,\n",
       "  'father': 118,\n",
       "  'still': 1045,\n",
       "  'eyes': 488,\n",
       "  'o': 896,\n",
       "  'seemed': 173,\n",
       "  'looked': 112,\n",
       "  'going': 653,\n",
       "  'home': 483,\n",
       "  'another': 413,\n",
       "  'head': 562,\n",
       "  'love': 1638,\n",
       "  'saw': 1655,\n",
       "  'having': 780,\n",
       "  'same': 1460,\n",
       "  'give': 407,\n",
       "  'looking': 112,\n",
       "  'aunt': 118,\n",
       "  'done': 1200,\n",
       "  'something': 749,\n",
       "  'myself': 910,\n",
       "  'face': 187,\n",
       "  'those': 1726,\n",
       "  'place': 1145,\n",
       "  'yet': 1549,\n",
       "  'd': 265,\n",
       "  'woman': 1737,\n",
       "  'poor': 1053,\n",
       "  'found': 1773,\n",
       "  'heart': 334,\n",
       "  'enough': 963,\n",
       "  'people': 801,\n",
       "  'sure': 754,\n",
       "  'just': 474,\n",
       "  'sister': 118,\n",
       "  'tell': 46,\n",
       "  'put': 276,\n",
       "  'off': 961,\n",
       "  'moment': 595,\n",
       "  'oh': 753,\n",
       "  'let': 1174,\n",
       "  'once': 1614,\n",
       "  'through': 751,\n",
       "  'n': 224,\n",
       "  'rather': 1624,\n",
       "  'hope': 550,\n",
       "  'got': 1222,\n",
       "  'under': 772,\n",
       "  'night': 619,\n",
       "  'l': 463,\n",
       "  'left': 992,\n",
       "  'between': 1780,\n",
       "  'took': 70,\n",
       "  'half': 1142,\n",
       "  'however': 1474,\n",
       "  'perhaps': 1751,\n",
       "  'new': 1204,\n",
       "  'yes': 753,\n",
       "  'world': 1028,\n",
       "  'whom': 1223,\n",
       "  'morning': 619,\n",
       "  'why': 753,\n",
       "  'r': 52,\n",
       "  'door': 664,\n",
       "  'indeed': 36,\n",
       "  'knew': 1272,\n",
       "  'family': 307,\n",
       "  'e': 958,\n",
       "  'against': 1211,\n",
       "  'j': 52,\n",
       "  'part': 323,\n",
       "  'because': 289,\n",
       "  'get': 89,\n",
       "  'seen': 840,\n",
       "  'heard': 840,\n",
       "  'things': 282,\n",
       "  'friend': 176,\n",
       "  'right': 1582,\n",
       "  'since': 289,\n",
       "  'three': 246,\n",
       "  'present': 193,\n",
       "  'men': 801,\n",
       "  'wish': 1971,\n",
       "  'f': 52,\n",
       "  'both': 1180,\n",
       "  'told': 46,\n",
       "  'gone': 89,\n",
       "  'words': 209,\n",
       "  'side': 85,\n",
       "  'years': 1063,\n",
       "  'find': 657,\n",
       "  'want': 401,\n",
       "  'less': 547,\n",
       "  'really': 671,\n",
       "  'few': 279,\n",
       "  'tlie': 1608,\n",
       "  'returned': 1475,\n",
       "  'speak': 1958,\n",
       "  'far': 243,\n",
       "  'believe': 1971,\n",
       "  'brother': 118,\n",
       "  'happy': 1131,\n",
       "  'round': 740,\n",
       "  'kind': 879,\n",
       "  'evening': 619,\n",
       "  'hear': 657,\n",
       "  'together': 492,\n",
       "  'else': 763,\n",
       "  'manner': 1262,\n",
       "  'sense': 701,\n",
       "  'feel': 27,\n",
       "  'best': 1419,\n",
       "  'till': 1928,\n",
       "  'tom': 194,\n",
       "  'towards': 1211,\n",
       "  'child': 1877,\n",
       "  'v': 5,\n",
       "  'almost': 1835,\n",
       "  'turned': 1277,\n",
       "  'cannot': 10,\n",
       "  'work': 1002,\n",
       "  'anything': 749,\n",
       "  'among': 340,\n",
       "  'letter': 580,\n",
       "  'gave': 878,\n",
       "  'sat': 331,\n",
       "  'hands': 1853,\n",
       "  'whole': 1136,\n",
       "  'each': 1370,\n",
       "  'next': 1149,\n",
       "  'name': 1855,\n",
       "  'began': 949,\n",
       "  'wife': 750,\n",
       "  'h': 52,\n",
       "  'least': 1940,\n",
       "  'sort': 879,\n",
       "  'often': 1233,\n",
       "  'voice': 1509,\n",
       "  'word': 406,\n",
       "  'course': 706,\n",
       "  'bad': 780,\n",
       "  'brought': 660,\n",
       "  'son': 750,\n",
       "  'end': 1521,\n",
       "  'leave': 1833,\n",
       "  'feeling': 1186,\n",
       "  'known': 1854,\n",
       "  'set': 1306,\n",
       "  'money': 1733,\n",
       "  'taken': 894,\n",
       "  'nor': 827,\n",
       "  'does': 1015,\n",
       "  'whether': 1632,\n",
       "  'cried': 146,\n",
       "  'john': 275,\n",
       "  'whose': 1019,\n",
       "  'given': 407,\n",
       "  'suppose': 1971,\n",
       "  'subject': 1066,\n",
       "  'days': 402,\n",
       "  'u': 463,\n",
       "  'general': 439,\n",
       "  'short': 1336,\n",
       "  'coming': 653,\n",
       "  'll': 265,\n",
       "  'light': 1748,\n",
       "  'called': 311,\n",
       "  'captain': 194,\n",
       "  'replied': 1475,\n",
       "  'mean': 401,\n",
       "  'feelings': 1498,\n",
       "  'within': 1098,\n",
       "  'gentleman': 344,\n",
       "  'business': 1627,\n",
       "  'opinion': 456,\n",
       "  'b': 759,\n",
       "  'strong': 462,\n",
       "  'pleasure': 1862,\n",
       "  'hour': 619,\n",
       "  're': 1936,\n",
       "  'state': 706,\n",
       "  'pretty': 695,\n",
       "  'deal': 1358,\n",
       "  'near': 1396,\n",
       "  'w': 958,\n",
       "  'rest': 1543,\n",
       "  'help': 575,\n",
       "  'used': 491,\n",
       "  'making': 781,\n",
       "  'jane': 742,\n",
       "  'passed': 1094,\n",
       "  'hardly': 623,\n",
       "  'husband': 118,\n",
       "  'ill': 1367,\n",
       "  'certainly': 1431,\n",
       "  'possible': 705,\n",
       "  'small': 1623,\n",
       "  'book': 686,\n",
       "  've': 78,\n",
       "  'keep': 168,\n",
       "  'idea': 181,\n",
       "  'air': 1082,\n",
       "  'table': 686,\n",
       "  'glad': 1131,\n",
       "  'person': 1737,\n",
       "  'nature': 398,\n",
       "  'asked': 1818,\n",
       "  'others': 482,\n",
       "  'c': 52,\n",
       "  'point': 585,\n",
       "  'park': 1832,\n",
       "  'alone': 1389,\n",
       "  'ought': 10,\n",
       "  'girl': 984,\n",
       "  'history': 388,\n",
       "  'doubt': 1666,\n",
       "  'matter': 1930,\n",
       "  'em': 560,\n",
       "  'care': 1405,\n",
       "  'children': 912,\n",
       "  'body': 509,\n",
       "  'ask': 1818,\n",
       "  'already': 1252,\n",
       "  'reason': 529,\n",
       "  'taking': 276,\n",
       "  'also': 1834,\n",
       "  'town': 722,\n",
       "  'character': 456,\n",
       "  'immediately': 738,\n",
       "  'daughter': 118,\n",
       "  'walked': 638,\n",
       "  'large': 1623,\n",
       "  'year': 1063,\n",
       "  'fine': 1875,\n",
       "  'case': 1090,\n",
       "  'until': 1928,\n",
       "  'means': 1666,\n",
       "  'friends': 242,\n",
       "  'anne': 379,\n",
       "  'able': 963,\n",
       "  'power': 1121,\n",
       "  'question': 1930,\n",
       "  'return': 508,\n",
       "  'account': 203,\n",
       "  'lie': 564,\n",
       "  'change': 1133,\n",
       "  'talk': 1958,\n",
       "  'open': 747,\n",
       "  'times': 1063,\n",
       "  'themselves': 482,\n",
       "  'answer': 736,\n",
       "  'david': 396,\n",
       "  'full': 1708,\n",
       "  'thomas': 1741,\n",
       "  'lo': 765,\n",
       "  'ready': 1612,\n",
       "  'chapter': 1044,\n",
       "  'sometimes': 1233,\n",
       "  'married': 450,\n",
       "  'true': 290,\n",
       "  'wanted': 358,\n",
       "  'bed': 1107,\n",
       "  'hard': 225,\n",
       "  'call': 1818,\n",
       "  'fire': 624,\n",
       "  'fellow': 1737,\n",
       "  'spoke': 310,\n",
       "  'seeing': 1178,\n",
       "  'longer': 1137,\n",
       "  'stood': 331,\n",
       "  'interest': 1862,\n",
       "  'yon': 315,\n",
       "  'street': 43,\n",
       "  'self': 701,\n",
       "  'walk': 952,\n",
       "  'bear': 351,\n",
       "  'high': 692,\n",
       "  'uncle': 118,\n",
       "  'yourself': 910,\n",
       "  'experience': 388,\n",
       "  'dinner': 459,\n",
       "  'doing': 1200,\n",
       "  'party': 1362,\n",
       "  'therefore': 708,\n",
       "  'thinking': 1411,\n",
       "  'everything': 486,\n",
       "  'certain': 1196,\n",
       "  'early': 1143,\n",
       "  'read': 1729,\n",
       "  'y': 463,\n",
       "  'boy': 147,\n",
       "  'beyond': 1098,\n",
       "  'usual': 1492,\n",
       "  'edward': 1732,\n",
       "  'master': 201,\n",
       "  'says': 1475,\n",
       "  'object': 1666,\n",
       "  'appeared': 468,\n",
       "  'fact': 1017,\n",
       "  'country': 1949,\n",
       "  'death': 1426,\n",
       "  'turn': 1277,\n",
       "  'visit': 1392,\n",
       "  'behind': 0,\n",
       "  'obliged': 605,\n",
       "  'god': 856,\n",
       "  'either': 1940,\n",
       "  'tone': 1509,\n",
       "  'use': 866,\n",
       "  'saying': 1475,\n",
       "  'personal': 388,\n",
       "  'happiness': 1300,\n",
       "  'understand': 401,\n",
       "  'kept': 1218,\n",
       "  'natural': 458,\n",
       "  'wished': 358,\n",
       "  'held': 905,\n",
       "  'low': 57,\n",
       "  'five': 246,\n",
       "  'likely': 1612,\n",
       "  'added': 1475,\n",
       "  'ii': 463,\n",
       "  'chair': 802,\n",
       "  'remember': 401,\n",
       "  'mary': 594,\n",
       "  'itself': 1316,\n",
       "  'window': 664,\n",
       "  'past': 691,\n",
       "  'doctor': 1911,\n",
       "  'arm': 867,\n",
       "  'four': 1259,\n",
       "  'lay': 331,\n",
       "  'ha': 78,\n",
       "  'attention': 76,\n",
       "  'london': 722,\n",
       "  'th': 224,\n",
       "  'observed': 1475,\n",
       "  'spirits': 1357,\n",
       "  'along': 751,\n",
       "  'second': 711,\n",
       "  'ladies': 1579,\n",
       "  'hair': 255,\n",
       "  'wonder': 1971,\n",
       "  'company': 356,\n",
       "  'sitting': 1446,\n",
       "  'above': 673,\n",
       "  'bring': 168,\n",
       "  'need': 10,\n",
       "  'king': 915,\n",
       "  'church': 307,\n",
       "  'became': 1788,\n",
       "  'expected': 1840,\n",
       "  'live': 1833,\n",
       "  'entered': 992,\n",
       "  'eye': 488,\n",
       "  'thus': 1880,\n",
       "  'except': 1387,\n",
       "  'comfort': 1862,\n",
       "  'dark': 1759,\n",
       "  'received': 1792,\n",
       "  'marriage': 1197,\n",
       "  'knowledge': 1121,\n",
       "  'view': 50,\n",
       "  'week': 62,\n",
       "  'lost': 144,\n",
       "  'speaking': 310,\n",
       "  'mine': 1878,\n",
       "  'common': 980,\n",
       "  'occasion': 1066,\n",
       "  'afraid': 754,\n",
       "  'met': 51,\n",
       "  'particular': 528,\n",
       "  'different': 1447,\n",
       "  'close': 1396,\n",
       "  'afterwards': 472,\n",
       "  'white': 507,\n",
       "  'getting': 276,\n",
       "  'late': 1143,\n",
       "  'thoughts': 1879,\n",
       "  'wrong': 1582,\n",
       "  'black': 755,\n",
       "  'loved': 1454,\n",
       "  'giving': 407,\n",
       "  'sent': 168,\n",
       "  'p': 463,\n",
       "  'nobody': 486,\n",
       "  'ma': 754,\n",
       "  'ten': 246,\n",
       "  'appearance': 1076,\n",
       "  'silence': 1129,\n",
       "  'truth': 1113,\n",
       "  'stay': 1833,\n",
       "  'answered': 1475,\n",
       "  'smile': 1857,\n",
       "  'show': 657,\n",
       "  'perfectly': 621,\n",
       "  'women': 801,\n",
       "  'hours': 402,\n",
       "  'minutes': 328,\n",
       "  'stairs': 951,\n",
       "  'conversation': 715,\n",
       "  'entirely': 1517,\n",
       "  'die': 89,\n",
       "  'ground': 85,\n",
       "  'sorry': 1524,\n",
       "  'turning': 1277,\n",
       "  'trouble': 557,\n",
       "  'water': 368,\n",
       "  'sit': 331,\n",
       "  'spirit': 909,\n",
       "  'instead': 1852,\n",
       "  'pride': 274,\n",
       "  'acquaintance': 1791,\n",
       "  'twenty': 655,\n",
       "  'meant': 633,\n",
       "  'elizabeth': 379,\n",
       "  'dead': 1554,\n",
       "  'tears': 337,\n",
       "  'agreeable': 1032,\n",
       "  'k': 958,\n",
       "  'quiet': 1822,\n",
       "  'adam': 194,\n",
       "  'tea': 459,\n",
       "  'ho': 962,\n",
       "  'neither': 827,\n",
       "  'affection': 1300,\n",
       "  'whatever': 839,\n",
       "  'form': 475,\n",
       "  'letters': 982,\n",
       "  'sight': 939,\n",
       "  'continued': 1934,\n",
       "  'forward': 128,\n",
       "  'seems': 173,\n",
       "  'henry': 596,\n",
       "  'easy': 1032,\n",
       "  'law': 829,\n",
       "  'bo': 808,\n",
       "  'happened': 1429,\n",
       "  'circumstances': 1068,\n",
       "  'meet': 657,\n",
       "  'cold': 784,\n",
       "  'worth': 458,\n",
       "  'ago': 472,\n",
       "  'real': 887,\n",
       "  'soul': 334,\n",
       "  'expression': 1694,\n",
       "  'drawing': 1348,\n",
       "  'purpose': 323,\n",
       "  'standing': 1446,\n",
       "  'become': 1271,\n",
       "  'tried': 978,\n",
       "  'greater': 136,\n",
       "  'dare': 1444,\n",
       "  'ah': 309,\n",
       "  'morrow': 1149,\n",
       "  'tliat': 443,\n",
       "  'determined': 497,\n",
       "  'walking': 952,\n",
       "  'hold': 1340,\n",
       "  'ia': 494,\n",
       "  'supposed': 1840,\n",
       "  'believed': 862,\n",
       "  'write': 168,\n",
       "  'former': 1228,\n",
       "  'fear': 550,\n",
       "  'probably': 1751,\n",
       "  'lived': 1271,\n",
       "  'effect': 1534,\n",
       "  'fell': 964,\n",
       "  'talked': 1958,\n",
       "  'lord': 856,\n",
       "  'cousin': 118,\n",
       "  'talking': 767,\n",
       "  'opened': 841,\n",
       "  'worse': 763,\n",
       "  'red': 507,\n",
       "  'pleasant': 1032,\n",
       "  'according': 969,\n",
       "  'deep': 57,\n",
       "  'considered': 1952,\n",
       "  'impossible': 299,\n",
       "  'thank': 1571,\n",
       "  'won': 630,\n",
       "  'living': 450,\n",
       "  'act': 1014,\n",
       "  'necessary': 705,\n",
       "  'tho': 1608,\n",
       "  'surprise': 809,\n",
       "  'society': 60,\n",
       "  'seem': 227,\n",
       "  'notice': 148,\n",
       "  'silent': 713,\n",
       "  'aa': 1374,\n",
       "  'order': 1041,\n",
       "  'knowing': 1272,\n",
       "  'pain': 45,\n",
       "  'beginning': 949,\n",
       "  'followed': 648,\n",
       "  'fortune': 1203,\n",
       "  'regard': 758,\n",
       "  'confidence': 1616,\n",
       "  'engaged': 378,\n",
       "  'knows': 367,\n",
       "  'none': 671,\n",
       "  'duty': 1047,\n",
       "  'sake': 1148,\n",
       "  'respect': 758,\n",
       "  'bit': 1265,\n",
       "  'exactly': 474,\n",
       "  'strange': 836,\n",
       "  'ly': 1586,\n",
       "  'fond': 553,\n",
       "  'pleased': 143,\n",
       "  'makes': 878,\n",
       "  'william': 596,\n",
       "  'laid': 88,\n",
       "  'sea': 1096,\n",
       "  'carriage': 28,\n",
       "  'school': 927,\n",
       "  'dick': 608,\n",
       "  'human': 1560,\n",
       "  'besides': 1717,\n",
       "  'looks': 112,\n",
       "  'please': 1818,\n",
       "  'gentlemen': 775,\n",
       "  'remained': 331,\n",
       "  'toward': 1211,\n",
       "  'settled': 613,\n",
       "  'six': 1259,\n",
       "  'colonel': 1673,\n",
       "  'during': 1116,\n",
       "  'several': 279,\n",
       "  'didn': 226,\n",
       "  'tbe': 1608,\n",
       "  'hundred': 95,\n",
       "  'try': 89,\n",
       "  'led': 743,\n",
       "  'price': 1319,\n",
       "  'public': 1867,\n",
       "  'handsome': 695,\n",
       "  'garden': 371,\n",
       "  'months': 1063,\n",
       "  'meeting': 1935,\n",
       "  'arms': 1853,\n",
       "  'marry': 1014,\n",
       "  'x': 5,\n",
       "  'aware': 114,\n",
       "  'merely': 1381,\n",
       "  'horse': 543,\n",
       "  'age': 195,\n",
       "  'presence': 1829,\n",
       "  'conduct': 590,\n",
       "  'anxious': 1111,\n",
       "  'thousand': 95,\n",
       "  'wi': 896,\n",
       "  'consider': 1971,\n",
       "  'opportunity': 672,\n",
       "  'situation': 590,\n",
       "  'figure': 332,\n",
       "  'clock': 791,\n",
       "  'comes': 1973,\n",
       "  'beauty': 392,\n",
       "  'charles': 596,\n",
       "  'cause': 1712,\n",
       "  'clear': 816,\n",
       "  'hat': 543,\n",
       "  'future': 691,\n",
       "  'desire': 1862,\n",
       "  'influence': 390,\n",
       "  'creature': 984,\n",
       "  'stand': 838,\n",
       "  'mentioned': 710,\n",
       "  'pounds': 1269,\n",
       "  'road': 1096,\n",
       "  'appear': 227,\n",
       "  'kindness': 1711,\n",
       "  'sound': 1563,\n",
       "  'story': 1113,\n",
       "  'easily': 602,\n",
       "  'position': 590,\n",
       "  'pocket': 386,\n",
       "  'play': 1958,\n",
       "  'pity': 1148,\n",
       "  'expect': 1971,\n",
       "  'sweet': 669,\n",
       "  'satisfied': 143,\n",
       "  'satisfaction': 1862,\n",
       "  'carried': 894,\n",
       "  'spite': 314,\n",
       "  'scarcely': 623,\n",
       "  'lips': 1150,\n",
       "  'pray': 910,\n",
       "  'england': 466,\n",
       "  'trust': 426,\n",
       "  'rose': 638,\n",
       "  'particularly': 1027,\n",
       "  'evil': 947,\n",
       "  'written': 1516,\n",
       "  'mere': 980,\n",
       "  'distance': 1521,\n",
       "  'beautiful': 669,\n",
       "  'speech': 30,\n",
       "  'consequence': 1529,\n",
       "  'fancy': 1971,\n",
       "  'pay': 533,\n",
       "  'bis': 277,\n",
       "  'perfect': 132,\n",
       "  'allow': 284,\n",
       "  'joy': 1711,\n",
       "  'glass': 335,\n",
       "  'assure': 401,\n",
       "  'sisters': 912,\n",
       "  'manners': 398,\n",
       "  'length': 1614,\n",
       "  'office': 725,\n",
       "  'waiting': 699,\n",
       "  'dress': 1700,\n",
       "  'especially': 1193,\n",
       "  'hoped': 920,\n",
       "  'g': 958,\n",
       "  'fixed': 375,\n",
       "  'surprised': 457,\n",
       "  'heaven': 856,\n",
       "  'note': 580,\n",
       "  'secret': 274,\n",
       "  'philip': 194,\n",
       "  'grave': 1945,\n",
       "  'spoken': 710,\n",
       "  'latter': 240,\n",
       "  'mention': 1135,\n",
       "  'putting': 276,\n",
       "  'suddenly': 77,\n",
       "  'pass': 89,\n",
       "  'leaving': 202,\n",
       "  'shook': 1596,\n",
       "  'breakfast': 459,\n",
       "  'fair': 1875,\n",
       "  'st': 597,\n",
       "  'directly': 738,\n",
       "  'understood': 1854,\n",
       "  'send': 168,\n",
       "  'james': 1741,\n",
       "  'trying': 978,\n",
       "  'wait': 1833,\n",
       "  'shut': 877,\n",
       "  'service': 1783,\n",
       "  'strength': 1219,\n",
       "  'run': 89,\n",
       "  'equal': 384,\n",
       "  'bright': 563,\n",
       "  'relation': 1328,\n",
       "  'hearing': 1178,\n",
       "  'writing': 541,\n",
       "  'repeated': 1475,\n",
       "  'heavy': 1955,\n",
       "  'paper': 612,\n",
       "  'advantage': 1862,\n",
       "  'arthur': 194,\n",
       "  'serious': 1839,\n",
       "  'journey': 1392,\n",
       "  'chance': 554,\n",
       "  'meaning': 50,\n",
       "  'otherwise': 1624,\n",
       "  'yesterday': 1149,\n",
       "  'died': 1648,\n",
       "  'liked': 39,\n",
       "  'taste': 1226,\n",
       "  'books': 982,\n",
       "  'proud': 553,\n",
       "  'cut': 1306,\n",
       "  'everybody': 486,\n",
       "  'further': 223,\n",
       "  'altogether': 1042,\n",
       "  'sudden': 1378,\n",
       "  'couldn': 226,\n",
       "  'comfortable': 1032,\n",
       "  'bat': 587,\n",
       "  'forth': 156,\n",
       "  'farther': 223,\n",
       "  'mill': 387,\n",
       "  'scene': 1935,\n",
       "  'imagine': 762,\n",
       "  'il': 130,\n",
       "  'delight': 1091,\n",
       "  'generally': 1169,\n",
       "  'struck': 393,\n",
       "  'feet': 342,\n",
       "  'thb': 387,\n",
       "  'court': 725,\n",
       "  'showed': 468,\n",
       "  'consciousness': 268,\n",
       "  'glance': 724,\n",
       "  'nearly': 1259,\n",
       "  'judgment': 456,\n",
       "  'stopped': 967,\n",
       "  'anybody': 749,\n",
       "  'seated': 1446,\n",
       "  'yours': 1878,\n",
       "  'hia': 277,\n",
       "  'walter': 1741,\n",
       "  'piece': 1265,\n",
       "  'wouldn': 226,\n",
       "  'paid': 533,\n",
       "  'broken': 788,\n",
       "  'bath': 722,\n",
       "  'girls': 1579,\n",
       "  'fall': 1217,\n",
       "  'difference': 1133,\n",
       "  'warm': 966,\n",
       "  'degree': 814,\n",
       "  'waa': 1310,\n",
       "  'slowly': 1512,\n",
       "  'temper': 1187,\n",
       "  'yard': 43,\n",
       "  'reply': 736,\n",
       "  'reading': 541,\n",
       "  'promise': 999,\n",
       "  'across': 751,\n",
       "  'box': 686,\n",
       "  'moments': 328,\n",
       "  'difficulty': 45,\n",
       "  'forget': 46,\n",
       "  'share': 1323,\n",
       "  'slight': 452,\n",
       "  'reached': 180,\n",
       "  'angry': 104,\n",
       "  'grant': 1641,\n",
       "  'greatest': 1307,\n",
       "  'finding': 1773,\n",
       "  'convinced': 114,\n",
       "  'engagement': 1935,\n",
       "  'plan': 323,\n",
       "  'boys': 1579,\n",
       "  'op': 396,\n",
       "  'step': 951,\n",
       "  'allowed': 965,\n",
       "  'private': 1867,\n",
       "  'begin': 870,\n",
       "  'presently': 738,\n",
       "  'sensibility': 410,\n",
       "  'tiie': 253,\n",
       "  'memory': 1654,\n",
       "  'ing': 17,\n",
       "  'music': 1046,\n",
       "  'health': 1357,\n",
       "  'english': 182,\n",
       "  'hopes': 490,\n",
       "  'sleep': 1107,\n",
       "  'excellent': 1343,\n",
       "  'danger': 554,\n",
       "  'admiration': 1711,\n",
       "  'loss': 1938,\n",
       "  'anxiety': 45,\n",
       "  'pale': 1701,\n",
       "  'resolved': 497,\n",
       "  'minute': 595,\n",
       "  'delighted': 143,\n",
       "  'ber': 165,\n",
       "  'opposite': 1206,\n",
       "  'rich': 695,\n",
       "  'mi': 958,\n",
       "  'pause': 699,\n",
       "  'seven': 246,\n",
       "  'sunday': 161,\n",
       "  'changed': 1704,\n",
       "  'companion': 176,\n",
       "  'servant': 1010,\n",
       "  'cottage': 333,\n",
       "  'weeks': 1063,\n",
       "  'miserable': 1811,\n",
       "  'property': 1203,\n",
       "  'quick': 1807,\n",
       "  'absence': 508,\n",
       "  'christian': 1925,\n",
       "  'following': 711,\n",
       "  'carry': 168,\n",
       "  'moved': 1510,\n",
       "  'seat': 802,\n",
       "  'hers': 1749,\n",
       "  'drew': 1754,\n",
       "  'difficult': 299,\n",
       "  'watch': 1890,\n",
       "  'rising': 120,\n",
       "  'nay': 309,\n",
       "  'news': 1147,\n",
       "  'weather': 42,\n",
       "  'green': 684,\n",
       "  'wind': 1243,\n",
       "  'extremely': 502,\n",
       "  'event': 1534,\n",
       "  'land': 1096,\n",
       "  'ay': 309,\n",
       "  'shaking': 1596,\n",
       "  'equally': 621,\n",
       "  'fresh': 1204,\n",
       "  'placed': 905,\n",
       "  'countenance': 488,\n",
       "  'free': 1923,\n",
       "  'number': 828,\n",
       "  'fit': 1752,\n",
       "  'hot': 1270,\n",
       "  'honor': 236,\n",
       "  'attachment': 1300,\n",
       "  'conscious': 114,\n",
       "  'due': 705,\n",
       "  'highly': 260,\n",
       "  'mark': 1044,\n",
       "  'hi': 958,\n",
       "  'touch': 921,\n",
       "  'period': 1584,\n",
       "  'beg': 376,\n",
       "  'raised': 120,\n",
       "  'picture': 1373,\n",
       "  'disposition': 1187,\n",
       "  'ihe': 1608,\n",
       "  'ran': 656,\n",
       "  'proper': 705,\n",
       "  'wishes': 266,\n",
       "  'wine': 1057,\n",
       "  'expressed': 228,\n",
       "  'foot': 93,\n",
       "  'plain': 816,\n",
       "  'misery': 436,\n",
       "  'dr': 594,\n",
       "  'action': 1694,\n",
       "  'maria': 596,\n",
       "  'begun': 1433,\n",
       "  'occurred': 1429,\n",
       "  'consideration': 1815,\n",
       "  'passage': 186,\n",
       "  'unless': 1130,\n",
       "  'somebody': 74,\n",
       "  'opening': 841,\n",
       "  'justice': 236,\n",
       "  'thrown': 894,\n",
       "  'arrived': 180,\n",
       "  'sensible': 87,\n",
       "  'burst': 311,\n",
       "  'gentle': 1618,\n",
       "  'mouth': 1150,\n",
       "  ...},\n",
       " 9956)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_centroid_map, len(word_centroid_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(word_centroid_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "['behind', 'stained', 'panes']\n",
      "\n",
      "Cluster 1\n",
      "['liking', 'preference']\n",
      "\n",
      "Cluster 2\n",
      "['cure', 'tion', 'bearing', 'doctrine', 'tendency', 'prophecy', 'species', 'gradual', 'development', 'bias', 'utility', 'consumption', 'import', 'diet', 'verge', 'analysis']\n",
      "\n",
      "Cluster 3\n",
      "['ice', 'blown', 'ocean', 'crooked', 'flies', 'sails', 'watery', 'brood', 'weed', 'isle', 'climb', 'honey', 'fuel', 'forests', 'gems', 'vegetation', 'shoots', 'multitudes', 'tides', 'sheds']\n",
      "\n",
      "Cluster 4\n",
      "['marked', 'coarse', 'polished', 'resembled', 'dissatisfied', 'adorned', 'moves', 'delicately', 'contrasted', 'disordered', 'gifted', 'richly', 'imaginable', 'settles']\n",
      "\n",
      "Cluster 5\n",
      "['v', 'x', 'iv', 'vi', 'vm', 'vl', 'vn', 'thk', 'problems']\n",
      "\n",
      "Cluster 6\n",
      "['fatal', 'decisive', 'speedy']\n",
      "\n",
      "Cluster 7\n",
      "['winked', 'complacently']\n",
      "\n",
      "Cluster 8\n",
      "['appointed', 'repaired', 'reappeared']\n",
      "\n",
      "Cluster 9\n",
      "['disturb', 'detain']\n"
     ]
    }
   ],
   "source": [
    "# For the first 10 clusters\n",
    "for cluster in range(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    #print \"\\nCluster %d\" #% cluster\n",
    "    print(f\"\\nCluster {cluster}\")\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    a_view = word_centroid_map.items()\n",
    "    tuples = list(a_view)\n",
    "    words = []\n",
    "    for i in range(0,len(word_centroid_map.values())):\n",
    "        if( tuples[i][1] == cluster ):\n",
    "            words.append(tuples[i][0])\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bag_of_centroids( wordlist, word_centroid_map ):\n",
    "    #\n",
    "    # The number of clusters is equal to the highest cluster index\n",
    "    # in the word / centroid map\n",
    "    num_centroids = max( word_centroid_map.values() ) + 1\n",
    "    #\n",
    "    # Pre-allocate the bag of centroids vector (for speed)\n",
    "    bag_of_centroids = np.zeros( num_centroids, dtype=\"float32\" )\n",
    "    #\n",
    "    # Loop over the words in the review. If the word is in the vocabulary,\n",
    "    # find which cluster it belongs to, and increment that cluster count \n",
    "    # by one\n",
    "    for word in wordlist:\n",
    "        if word in word_centroid_map:\n",
    "            index = word_centroid_map[word]\n",
    "            bag_of_centroids[index] += 1\n",
    "    #\n",
    "    # Return the \"bag of centroids\"\n",
    "    return bag_of_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-allocate an array for the training set bags of centroids (for speed)\n",
    "train_centroids = np.zeros( (train[\"text\"].size, int(num_clusters)), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "# Transform the training set reviews into bags of centroids\n",
    "counter = 0\n",
    "for review in clean_train_reviews:\n",
    "    train_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1\n",
    "\n",
    "# Repeat for test reviews \n",
    "test_centroids = np.zeros((test[\"text\"].size, int(num_clusters)), \\\n",
    "    dtype=\"float32\" )\n",
    "\n",
    "counter = 0\n",
    "for review in clean_test_reviews:\n",
    "    test_centroids[counter] = create_bag_of_centroids( review, \\\n",
    "        word_centroid_map )\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                  5784\n",
       "text      misfortune to have an uncle who died leaving h...\n",
       "author                                                    8\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting a random forest to labeled training data...\n"
     ]
    }
   ],
   "source": [
    "# This cell take some minutes\n",
    "# Fit a random forest and extract predictions \n",
    "forest = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# Fitting the forest may take a few minutes\n",
    "print(\"Fitting a random forest to labeled training data...\")\n",
    "forest = forest.fit(train_centroids,train[\"author\"])\n",
    "result = forest.predict(test_centroids)\n",
    "\n",
    "# Write the test results \n",
    "output = pd.DataFrame(data={\"true_author\":test[\"author\"], \"pred_author\":result})\n",
    "output.to_csv( \"BagOfCentroidsAuthor.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_author</th>\n",
       "      <th>pred_author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2421</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2422</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2423</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2425</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2426 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      true_author  pred_author\n",
       "0               8            8\n",
       "1              14           14\n",
       "2               8            8\n",
       "3              26           26\n",
       "4               8            8\n",
       "...           ...          ...\n",
       "2421           26           26\n",
       "2422           14           14\n",
       "2423           14           14\n",
       "2424           26           26\n",
       "2425           14           14\n",
       "\n",
       "[2426 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted   8    14   26\n",
      "Actural                 \n",
      "8          756   28    5\n",
      "14           8  834    6\n",
      "26           2    3  784\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix = pd.crosstab(output['true_author'], output['pred_author'], rownames=['Actural'], colnames=['Predicted'])\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[756,  28,   5],\n",
       "       [  8, 834,   6],\n",
       "       [  2,   3, 784]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.confusion_matrix(output['true_author'], output['pred_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.98694517, 0.96416185, 0.98616352]),\n",
       " array([0.9581749 , 0.98349057, 0.99366286]),\n",
       " array([0.97234727, 0.9737303 , 0.98989899]),\n",
       " array([789, 848, 789], dtype=int64))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.precision_recall_fscore_support(output['true_author'], output['pred_author'], average=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
